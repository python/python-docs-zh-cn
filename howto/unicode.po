# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2001-2024, Python Software Foundation
# This file is distributed under the same license as the Python package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# Konge <zkonge@outlook.com>, 2021
# allenjuly7 <allenjuly7@astu.fun>, 2021
# ppcfish <ppcfish@gmail.com>, 2021
# Xu Siyuan, 2021
# Dai Xu <daixu61@hotmail.com>, 2021
# meowmeowcat <meowmeowcat1211@gmail.com>, 2021
# Alpha Du <alphanow@gmail.com>, 2022
# ProgramRipper, 2023
# lian Wu (Wulian) <xiguawulian@gmail.com>, 2024
# Freesand Leo <yuqinju@163.com>, 2024
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python 3.13\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-10-04 14:17+0000\n"
"PO-Revision-Date: 2021-06-28 00:53+0000\n"
"Last-Translator: Freesand Leo <yuqinju@163.com>, 2024\n"
"Language-Team: Chinese (China) (https://app.transifex.com/python-doc/teams/5390/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../howto/unicode.rst:5
msgid "Unicode HOWTO"
msgstr "Unicode æŒ‡å—"

#: ../../howto/unicode.rst:0
msgid "Release"
msgstr "å‘å¸ƒç‰ˆæœ¬"

#: ../../howto/unicode.rst:7
msgid "1.12"
msgstr "1.12"

#: ../../howto/unicode.rst:9
msgid ""
"This HOWTO discusses Python's support for the Unicode specification for "
"representing textual data, and explains various problems that people "
"commonly encounter when trying to work with Unicode."
msgstr "æœ¬æ–‡ä»‹ç»äº† Python å¯¹è¡¨ç¤ºæ–‡æœ¬æ•°æ®çš„ Unicode è§„èŒƒçš„æ”¯æŒï¼Œå¹¶å¯¹å„ç§ Unicode å¸¸è§ä½¿ç”¨é—®é¢˜åšäº†è§£é‡Šã€‚"

#: ../../howto/unicode.rst:15
msgid "Introduction to Unicode"
msgstr "Unicode æ¦‚è¿°"

#: ../../howto/unicode.rst:18
msgid "Definitions"
msgstr "å®šä¹‰"

#: ../../howto/unicode.rst:20
msgid ""
"Today's programs need to be able to handle a wide variety of characters.  "
"Applications are often internationalized to display messages and output in a"
" variety of user-selectable languages; the same program might need to output"
" an error message in English, French, Japanese, Hebrew, or Russian.  Web "
"content can be written in any of these languages and can also include a "
"variety of emoji symbols. Python's string type uses the Unicode Standard for"
" representing characters, which lets Python programs work with all these "
"different possible characters."
msgstr ""
"å¦‚ä»Šçš„ç¨‹åºéœ€è¦èƒ½å¤Ÿå¤„ç†å„ç§å„æ ·çš„å­—ç¬¦ã€‚åº”ç”¨ç¨‹åºé€šå¸¸åšäº†å›½é™…åŒ–å¤„ç†ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸åŒçš„è¯­è¨€æ˜¾ç¤ºä¿¡æ¯å’Œè¾“å‡ºæ•°æ®ã€‚åŒä¸€ä¸ªç¨‹åºå¯èƒ½éœ€è¦ä»¥è‹±è¯­ã€æ³•è¯­ã€æ—¥è¯­ã€å¸Œä¼¯æ¥è¯­æˆ–ä¿„è¯­è¾“å‡ºé”™è¯¯ä¿¡æ¯ã€‚ç½‘é¡µå†…å®¹å¯èƒ½ç”±è¿™äº›è¯­è¨€ä¹¦å†™ï¼Œå¹¶ä¸”å¯èƒ½åŒ…å«ä¸åŒçš„è¡¨æƒ…ç¬¦å·ã€‚Python"
" çš„å­—ç¬¦ä¸²ç±»å‹é‡‡ç”¨ Unicode æ ‡å‡†æ¥è¡¨ç¤ºå­—ç¬¦ï¼Œä½¿å¾— Python ç¨‹åºèƒ½å¤Ÿæ­£å¸¸å¤„ç†æ‰€æœ‰è¿™äº›ä¸åŒçš„å­—ç¬¦ã€‚"

#: ../../howto/unicode.rst:30
msgid ""
"Unicode (https://www.unicode.org/) is a specification that aims to list "
"every character used by human languages and give each character its own "
"unique code.  The Unicode specifications are continually revised and updated"
" to add new languages and symbols."
msgstr ""
"Unicode "
"è§„èŒƒï¼ˆhttps://www.unicode.org/ï¼‰æ—¨åœ¨ç½—åˆ—äººç±»è¯­è¨€æ‰€ç”¨åˆ°çš„æ‰€æœ‰å­—ç¬¦ï¼Œå¹¶èµ‹äºˆæ¯ä¸ªå­—ç¬¦å”¯ä¸€çš„ç¼–ç ã€‚è¯¥è§„èŒƒä¸€ç›´åœ¨è¿›è¡Œä¿®è®¢å’Œæ›´æ–°ï¼Œä¸æ–­åŠ å…¥æ–°çš„è¯­ç§å’Œç¬¦å·ã€‚"

#: ../../howto/unicode.rst:35
msgid ""
"A **character** is the smallest possible component of a text.  'A', 'B', "
"'C', etc., are all different characters.  So are 'Ãˆ' and 'Ã'.  Characters "
"vary depending on the language or context you're talking about.  For "
"example, there's a character for \"Roman Numeral One\", 'â… ', that's separate"
" from the uppercase letter 'I'.  They'll usually look the same, but these "
"are two different characters that have different meanings."
msgstr ""
"ä¸€ä¸ª **å­—ç¬¦** æ˜¯æ–‡æœ¬çš„æœ€å°ç»„ä»¶ã€‚â€˜Aâ€™ã€â€˜Bâ€™ã€â€˜Câ€™ ç­‰éƒ½æ˜¯ä¸åŒçš„å­—ç¬¦ã€‚â€˜Ãˆâ€™ å’Œ â€˜Ãâ€™ "
"ä¹Ÿä¸€æ ·ã€‚å­—ç¬¦ä¼šéšç€è¯­è¨€æˆ–è€…ä¸Šä¸‹æ–‡çš„å˜åŒ–è€Œå˜åŒ–ã€‚æ¯”å¦‚ï¼Œâ€˜â… â€™ æ˜¯ä¸€ä¸ªè¡¨ç¤º â€œç½—é©¬æ•°å­— 1â€ çš„å­—ç¬¦ï¼Œå®ƒä¸å¤§å†™å­—æ¯ â€˜Iâ€™ "
"ä¸åŒã€‚ä»–ä»¬å¾€å¾€çœ‹èµ·æ¥ç›¸åŒï¼Œä½†è¿™æ˜¯ä¸¤ä¸ªæœ‰ç€ä¸åŒå«ä¹‰çš„å­—ç¬¦ã€‚"

#: ../../howto/unicode.rst:42
msgid ""
"The Unicode standard describes how characters are represented by **code "
"points**.  A code point value is an integer in the range 0 to 0x10FFFF "
"(about 1.1 million values, the `actual number assigned "
"<https://www.unicode.org/versions/latest/#Summary>`_ is less than that). In "
"the standard and in this document, a code point is written using the "
"notation ``U+265E`` to mean the character with value ``0x265e`` (9,822 in "
"decimal)."
msgstr ""
"Unicode æ ‡å‡†æè¿°äº†å­—ç¬¦æ˜¯å¦‚ä½•ç”¨ **ç ä½ï¼ˆcode pointï¼‰** è¡¨ç¤ºçš„ã€‚ç ä½çš„å–å€¼èŒƒå›´æ˜¯ 0 åˆ° 0x10FFFF çš„æ•´æ•°ï¼ˆå¤§çº¦ 110 "
"ä¸‡ä¸ªå€¼ï¼Œ`å®é™…åˆ†é…çš„æ•°å­— <https://www.unicode.org/versions/latest/#Summary>`_ æ²¡æœ‰é‚£ä¹ˆå¤šï¼‰ã€‚åœ¨ "
"Unicode æ ‡å‡†å’Œæœ¬æ–‡ä¸­ï¼Œç ä½é‡‡ç”¨ ``U+265E`` çš„å½¢å¼ï¼Œè¡¨ç¤ºå€¼ä¸º ``0x265e`` çš„å­—ç¬¦ï¼ˆåè¿›åˆ¶ä¸º 9822ï¼‰ã€‚"

#: ../../howto/unicode.rst:50
msgid ""
"The Unicode standard contains a lot of tables listing characters and their "
"corresponding code points:"
msgstr "Unicode æ ‡å‡†ä¸­åŒ…å«äº†è®¸å¤šè¡¨æ ¼ï¼Œåˆ—å‡ºäº†å¾ˆå¤šå­—ç¬¦åŠå…¶å¯¹åº”çš„ç ä½ã€‚"

#: ../../howto/unicode.rst:53
msgid ""
"0061    'a'; LATIN SMALL LETTER A\n"
"0062    'b'; LATIN SMALL LETTER B\n"
"0063    'c'; LATIN SMALL LETTER C\n"
"...\n"
"007B    '{'; LEFT CURLY BRACKET\n"
"...\n"
"2167    'â…§'; ROMAN NUMERAL EIGHT\n"
"2168    'â…¨'; ROMAN NUMERAL NINE\n"
"...\n"
"265E    'â™'; BLACK CHESS KNIGHT\n"
"265F    'â™Ÿ'; BLACK CHESS PAWN\n"
"...\n"
"1F600   'ğŸ˜€'; GRINNING FACE\n"
"1F609   'ğŸ˜‰'; WINKING FACE\n"
"..."
msgstr ""
"0061    'a'; æ‹‰ä¸å­—æ¯ A å°å†™\n"
"0062    'b'; æ‹‰ä¸å­—æ¯ B å°å†™\n"
"0063    'c'; æ‹‰ä¸å­—æ¯ C å°å†™\n"
"...\n"
"007B    '{'; å·¦èŠ±æ‹¬å·\n"
"...\n"
"2167    'â…§'; ç½—é©¬æ•°å­—å…«\n"
"2168    'â…¨'; ç½—é©¬æ•°å­—ä¹\n"
"...\n"
"265E    'â™'; å›½é™…è±¡æ£‹é»‘é©¬\n"
"265F    'â™Ÿ'; å›½é™…è±¡æ£‹é»‘å…µ\n"
"...\n"
"1F600   'ğŸ˜€'; å¾®ç¬‘è„¸\n"
"1F609   'ğŸ˜‰'; çœ¨çœ¼è„¸\n"
"..."

#: ../../howto/unicode.rst:71
msgid ""
"Strictly, these definitions imply that it's meaningless to say 'this is "
"character ``U+265E``'.  ``U+265E`` is a code point, which represents some "
"particular character; in this case, it represents the character 'BLACK CHESS"
" KNIGHT', 'â™'.  In informal contexts, this distinction between code points "
"and characters will sometimes be forgotten."
msgstr ""
"ä¸¥æ ¼åœ°è¯´ï¼Œä¸Šè¿°å®šä¹‰æš—ç¤ºäº†ä»¥ä¸‹è¯´æ³•æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼šâ€œè¿™æ˜¯å­—ç¬¦ ``U+265E``â€ã€‚``U+265E`` "
"åªæ˜¯ä¸€ä¸ªç ä½ï¼Œä»£è¡¨æŸä¸ªç‰¹å®šçš„å­—ç¬¦ï¼›è¿™é‡Œå®ƒä»£è¡¨äº†å­—ç¬¦ â€œå›½é™…è±¡æ£‹é»‘éª‘å£«â€ 'â™'ã€‚åœ¨éæ­£å¼çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæœ‰æ—¶ä¼šå¿½ç•¥ç ä½å’Œå­—ç¬¦çš„åŒºåˆ«ã€‚"

#: ../../howto/unicode.rst:78
msgid ""
"A character is represented on a screen or on paper by a set of graphical "
"elements that's called a **glyph**.  The glyph for an uppercase A, for "
"example, is two diagonal strokes and a horizontal stroke, though the exact "
"details will depend on the font being used.  Most Python code doesn't need "
"to worry about glyphs; figuring out the correct glyph to display is "
"generally the job of a GUI toolkit or a terminal's font renderer."
msgstr ""
"ä¸€ä¸ªå­—ç¬¦åœ¨å±å¹•æˆ–çº¸ä¸Šè¢«è¡¨ç¤ºä¸ºä¸€ç»„å›¾å½¢å…ƒç´ ï¼Œè¢«ç§°ä¸º **å­—å½¢ï¼ˆglyphï¼‰** ã€‚æ¯”å¦‚ï¼Œå¤§å†™å­—æ¯ A "
"çš„å­—å½¢ï¼Œæ˜¯ä¸¤ç¬”æ–œçº¿å’Œä¸€ç¬”æ¨ªçº¿ï¼Œè€Œå…·ä½“çš„ç»†èŠ‚å–å†³äºæ‰€ä½¿ç”¨çš„å­—ä½“ã€‚å¤§éƒ¨åˆ† Python ä»£ç ä¸å¿…æ‹…å¿ƒå­—å½¢ï¼Œæ‰¾åˆ°æ­£ç¡®çš„æ˜¾ç¤ºå­—å½¢é€šå¸¸æ˜¯äº¤ç»™ GUI "
"å·¥å…·åŒ…æˆ–ç»ˆç«¯çš„å­—ä½“æ¸²æŸ“ç¨‹åºæ¥å®Œæˆã€‚"

#: ../../howto/unicode.rst:87
msgid "Encodings"
msgstr "ç¼–ç "

#: ../../howto/unicode.rst:89
msgid ""
"To summarize the previous section: a Unicode string is a sequence of code "
"points, which are numbers from 0 through ``0x10FFFF`` (1,114,111 decimal).  "
"This sequence of code points needs to be represented in memory as a set of "
"**code units**, and **code units** are then mapped to 8-bit bytes.  The "
"rules for translating a Unicode string into a sequence of bytes are called a"
" **character encoding**, or just an **encoding**."
msgstr ""
"ä¸Šä¸€æ®µå¯ä»¥å½’ç»“ä¸ºï¼šä¸€ä¸ª Unicode å­—ç¬¦ä¸²æ˜¯ä¸€ç³»åˆ—ç ä½ï¼ˆä» 0 åˆ° ``0x10FFFF`` æˆ–è€…è¯´åè¿›åˆ¶çš„ 1,114,111 "
"çš„æ•°å­—ï¼‰ç»„æˆçš„åºåˆ—ã€‚è¿™ä¸€åºåˆ—åœ¨å†…å­˜ä¸­éœ€è¢«è¡¨ç¤ºä¸ºä¸€ç»„ **ç å…ƒï¼ˆcode unitï¼‰** ï¼Œ **ç å…ƒ** ä¼šæ˜ å°„æˆåŒ…å«å…«ä¸ªäºŒè¿›åˆ¶ä½çš„å­—èŠ‚ã€‚å°† "
"Unicode å­—ç¬¦ä¸²ç¿»è¯‘æˆå­—èŠ‚åºåˆ—çš„è§„åˆ™ç§°ä¸º **å­—ç¬¦ç¼–ç ** ï¼Œæˆ–è€… **ç¼–ç ** ã€‚"

#: ../../howto/unicode.rst:97
msgid ""
"The first encoding you might think of is using 32-bit integers as the code "
"unit, and then using the CPU's representation of 32-bit integers. In this "
"representation, the string \"Python\" might look like this:"
msgstr ""
"å¤§å®¶é¦–å…ˆä¼šæƒ³åˆ°çš„ç¼–ç å¯èƒ½æ˜¯ç”¨ 32 ä½çš„æ•´æ•°ä½œä¸ºä»£ç ä½ï¼Œç„¶åé‡‡ç”¨ CPU å¯¹ 32 ä½æ•´æ•°çš„è¡¨ç¤ºæ³•ã€‚å­—ç¬¦ä¸² â€œPythonâ€ "
"ç”¨è¿™ç§è¡¨ç¤ºæ³•å¯èƒ½ä¼šå¦‚ä¸‹æ‰€ç¤ºï¼š"

#: ../../howto/unicode.rst:101
msgid ""
"   P           y           t           h           o           n\n"
"0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00\n"
"   0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23"
msgstr ""
"   P           y           t           h           o           n\n"
"0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00\n"
"   0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23"

#: ../../howto/unicode.rst:107
msgid ""
"This representation is straightforward but using it presents a number of "
"problems."
msgstr "è¿™ç§è¡¨ç¤ºæ³•éå¸¸ç›´ç™½ï¼Œä½†ä¹Ÿå­˜åœ¨ ä¸€äº›é—®é¢˜ã€‚"

#: ../../howto/unicode.rst:110
msgid "It's not portable; different processors order the bytes differently."
msgstr "ä¸å…·å¯ç§»æ¤æ€§ï¼›ä¸åŒçš„å¤„ç†å™¨çš„å­—èŠ‚åºä¸åŒã€‚"

#: ../../howto/unicode.rst:112
msgid ""
"It's very wasteful of space.  In most texts, the majority of the code points"
" are less than 127, or less than 255, so a lot of space is occupied by "
"``0x00`` bytes.  The above string takes 24 bytes compared to the 6 bytes "
"needed for an ASCII representation.  Increased RAM usage doesn't matter too "
"much (desktop computers have gigabytes of RAM, and strings aren't usually "
"that large), but expanding our usage of disk and network bandwidth by a "
"factor of 4 is intolerable."
msgstr ""
"éå¸¸æµªè´¹ç©ºé—´ã€‚ åœ¨å¤§å¤šæ•°æ–‡æœ¬ä¸­ï¼Œå¤§éƒ¨åˆ†ç ä½éƒ½å°äº 127 æˆ– 255ï¼Œå› æ­¤å­—èŠ‚ ``0x00`` å ç”¨äº†å¤§é‡ç©ºé—´ã€‚ç›¸è¾ƒäº ASCII è¡¨ç¤ºæ³•æ‰€éœ€çš„ 6 "
"ä¸ªå­—èŠ‚ï¼Œä»¥ä¸Šå­—ç¬¦ä¸²éœ€è¦å ç”¨ 24 ä¸ªå­—èŠ‚ã€‚RAM ç”¨é‡çš„å¢åŠ æ²¡é‚£ä¹ˆè¦ç´§ï¼ˆå°å¼è®¡ç®—æœºæœ‰æˆ GB çš„ "
"RAMï¼Œè€Œå­—ç¬¦ä¸²é€šå¸¸ä¸ä¼šæœ‰é‚£ä¹ˆå¤§ï¼‰ï¼Œä½†è¦æŠŠç£ç›˜å’Œç½‘ç»œå¸¦å®½çš„ç”¨é‡å¢åŠ  4 å€æ˜¯æ— æ³•å¿å—çš„ã€‚"

#: ../../howto/unicode.rst:120
msgid ""
"It's not compatible with existing C functions such as ``strlen()``, so a new"
" family of wide string functions would need to be used."
msgstr "ä¸ç°æœ‰çš„ C å‡½æ•°ï¼ˆå¦‚ ``strlen()`` ï¼‰ä¸å…¼å®¹ï¼Œå› æ­¤éœ€è¦é‡‡ç”¨ä¸€å¥—æ–°çš„å®½å­—ç¬¦ä¸²å‡½æ•°ã€‚"

#: ../../howto/unicode.rst:123
msgid ""
"Therefore this encoding isn't used very much, and people instead choose "
"other encodings that are more efficient and convenient, such as UTF-8."
msgstr "å› æ­¤è¿™ç§ç¼–ç ç”¨å¾—ä¸å¤šï¼Œäººä»¬è½¬è€Œé€‰æ‹©å…¶ä»–æ›´é«˜æ•ˆã€æ›´æ–¹ä¾¿çš„ç¼–ç ï¼Œæ¯”å¦‚ UTF-8ã€‚"

#: ../../howto/unicode.rst:126
msgid ""
"UTF-8 is one of the most commonly used encodings, and Python often defaults "
"to using it.  UTF stands for \"Unicode Transformation Format\", and the '8' "
"means that 8-bit values are used in the encoding.  (There are also UTF-16 "
"and UTF-32 encodings, but they are less frequently used than UTF-8.)  UTF-8 "
"uses the following rules:"
msgstr ""
"UTF-8 æ˜¯æœ€å¸¸ç”¨çš„ç¼–ç ä¹‹ä¸€ï¼ŒPython å¾€å¾€é»˜è®¤ä¼šé‡‡ç”¨å®ƒã€‚UTF ä»£è¡¨â€œUnicode Transformation Formatâ€ï¼Œ'8' "
"è¡¨ç¤ºç¼–ç é‡‡ç”¨ 8 ä½æ•°ã€‚ï¼ˆUTF-16 å’Œ UTF-32 ç¼–ç ä¹Ÿæ˜¯å­˜åœ¨çš„ï¼Œä½†å…¶ä½¿ç”¨é¢‘ç‡ä¸å¦‚ UTF-8ã€‚ï¼‰UTF-8 çš„è§„åˆ™å¦‚ä¸‹ï¼š"

#: ../../howto/unicode.rst:132
msgid ""
"If the code point is < 128, it's represented by the corresponding byte "
"value."
msgstr "å¦‚æœç ä½ < 128ï¼Œåˆ™ç›´æ¥ç”¨å¯¹åº”çš„å­—èŠ‚å€¼è¡¨ç¤ºã€‚"

#: ../../howto/unicode.rst:133
msgid ""
"If the code point is >= 128, it's turned into a sequence of two, three, or "
"four bytes, where each byte of the sequence is between 128 and 255."
msgstr "å¦‚æœç ä½  >= 128ï¼Œåˆ™è½¬æ¢ä¸º 2ã€3ã€4 ä¸ªå­—èŠ‚çš„åºåˆ—ï¼Œæ¯ä¸ªå­—èŠ‚å€¼éƒ½ä½äº 128 å’Œ 255 ä¹‹é—´ã€‚"

#: ../../howto/unicode.rst:136
msgid "UTF-8 has several convenient properties:"
msgstr "UTF-8 æœ‰å‡ ä¸ªå¾ˆæ–¹ä¾¿çš„ç‰¹æ€§ï¼š"

#: ../../howto/unicode.rst:138
msgid "It can handle any Unicode code point."
msgstr "å¯ä»¥å¤„ç†ä»»ä½• Unicode ç ä½ã€‚"

#: ../../howto/unicode.rst:139
msgid ""
"A Unicode string is turned into a sequence of bytes that contains embedded "
"zero bytes only where they represent the null character (U+0000). This means"
" that UTF-8 strings can be processed by C functions such as ``strcpy()`` and"
" sent through protocols that can't handle zero bytes for anything other than"
" end-of-string markers."
msgstr ""
"Unicode å­—ç¬¦ä¸²è¢«è½¬æ¢ä¸ºä¸€ä¸ªå­—èŠ‚åºåˆ—ï¼Œä»…åœ¨è¡¨ç¤ºç©ºï¼ˆnull ï¼‰å­—ç¬¦ï¼ˆU+0000ï¼‰æ—¶æ‰ä¼šåŒ…å«é›¶å€¼çš„å­—èŠ‚ã€‚è¿™æ„å‘³ç€ ``strcpy()`` "
"ä¹‹ç±»çš„C å‡½æ•°å¯ä»¥å¤„ç† UTF-8 å­—ç¬¦ä¸²ï¼Œè€Œä¸”ç”¨é‚£äº›ä¸èƒ½å¤„ç†å­—ç¬¦ä¸²ç»“æŸç¬¦ä¹‹å¤–çš„é›¶å€¼å­—èŠ‚çš„åè®®ä¹Ÿèƒ½å‘é€ã€‚"

#: ../../howto/unicode.rst:144
msgid "A string of ASCII text is also valid UTF-8 text."
msgstr "ASCII å­—ç¬¦ä¸²ä¹Ÿæ˜¯ä¹Ÿæ˜¯ä¹Ÿæ˜¯åˆæ³•çš„ UTF-8 æ–‡æœ¬ã€‚"

#: ../../howto/unicode.rst:145
msgid ""
"UTF-8 is fairly compact; the majority of commonly used characters can be "
"represented with one or two bytes."
msgstr "UTF-8 ç›¸å½“ç´§å‡‘ï¼›å¤§å¤šæ•°å¸¸ç”¨å­—ç¬¦å‡å¯ç”¨ä¸€ä¸¤ä¸ªå­—èŠ‚è¡¨ç¤ºã€‚"

#: ../../howto/unicode.rst:147
msgid ""
"If bytes are corrupted or lost, it's possible to determine the start of the "
"next UTF-8-encoded code point and resynchronize.  It's also unlikely that "
"random 8-bit data will look like valid UTF-8."
msgstr ""
"å¦‚æœå­—èŠ‚æ•°æ®è¢«æŸåæˆ–ä¸¢å¤±ï¼Œåˆ™å¯ä»¥æ‰¾å‡ºä¸‹ä¸€ä¸ª UTF-8 ç ç‚¹çš„å¼€å§‹ä½ç½®å¹¶é‡æ–°å¼€å§‹åŒæ­¥ã€‚éšæœºçš„ 8 ä½æ•°æ®ä¹Ÿä¸å¤ªå¯èƒ½åƒæ˜¯æœ‰æ•ˆçš„ UTF-8 ç¼–ç ã€‚"

#: ../../howto/unicode.rst:150
msgid ""
"UTF-8 is a byte oriented encoding. The encoding specifies that each "
"character is represented by a specific sequence of one or more bytes. This "
"avoids the byte-ordering issues that can occur with integer and word "
"oriented encodings, like UTF-16 and UTF-32, where the sequence of bytes "
"varies depending on the hardware on which the string was encoded."
msgstr ""
"UTF-8 æ˜¯ä¸€ç§é¢å‘å­—èŠ‚çš„ç¼–ç ã€‚ç¼–ç è§„å®šäº†æ¯ä¸ªå­—ç¬¦ç”±ä¸€ä¸ªæˆ–å¤šä¸ªå­—èŠ‚çš„åºåˆ—è¡¨ç¤ºã€‚è¿™é¿å…äº†æ•´æ•°å’ŒåŒå­—èŠ‚ç¼–ç ï¼ˆå¦‚ UTF-16 å’Œ "
"UTF-32ï¼‰å¯èƒ½å‡ºç°çš„å­—èŠ‚é¡ºåºé—®é¢˜ï¼Œé‚£æ—¶çš„å­—èŠ‚åºåˆ—ä¼šå› æ‰§è¡Œç¼–ç çš„ç¡¬ä»¶è€Œå¼‚ã€‚"

#: ../../howto/unicode.rst:158 ../../howto/unicode.rst:514
#: ../../howto/unicode.rst:735
msgid "References"
msgstr "å‚è€ƒæ–‡çŒ®"

#: ../../howto/unicode.rst:160
msgid ""
"The `Unicode Consortium site <https://www.unicode.org>`_ has character "
"charts, a glossary, and PDF versions of the Unicode specification.  Be "
"prepared for some difficult reading.  `A chronology "
"<https://www.unicode.org/history/>`_ of the origin and development of "
"Unicode is also available on the site."
msgstr ""
"`Unicode Consortium ç«™ç‚¹ <https://www.unicode.org>`_ åŒ…å« Unicode è§„èŒƒçš„å­—ç¬¦å›¾è¡¨ã€è¯æ±‡è¡¨å’Œ "
"PDF ç‰ˆæœ¬ã€‚è¯·åšå¥½å‡†å¤‡ï¼Œæœ‰äº›å†…å®¹è¯»èµ·æ¥æœ‰ç‚¹éš¾åº¦ã€‚è¯¥ç½‘ç«™ä¸Šè¿˜æä¾›äº† Unicode èµ·æºå’Œå‘å±•çš„ `å¹´è¡¨ "
"<https://www.unicode.org/history/>`_ ã€‚"

#: ../../howto/unicode.rst:165
msgid ""
"On the Computerphile Youtube channel, Tom Scott briefly `discusses the "
"history of Unicode and UTF-8 <https://www.youtube.com/watch?v=MijmeoH9LT4>`_"
" (9 minutes 36 seconds)."
msgstr ""
"åœ¨ Computerphile çš„ Youtube é¢‘é“ä¸Šï¼ŒTom Scott ç®€è¦åœ° `è®¨è®ºäº† Unicode å’Œ UTF-8 "
"<https://www.youtube.com/watch?v=MijmeoH9LT4>`_ ï¼ˆ9 åˆ† 36 ç§’ï¼‰çš„å†å²ã€‚"

#: ../../howto/unicode.rst:169
msgid ""
"To help understand the standard, Jukka Korpela has written `an introductory "
"guide <https://jkorpela.fi/unicode/guide.html>`_ to reading the Unicode "
"character tables."
msgstr ""
"ä¸ºäº†å¸®åŠ©ç†è§£è¯¥æ ‡å‡†ï¼ŒJukka Korpela ç¼–å†™äº†é˜…è¯» Unicode å­—ç¬¦è¡¨çš„ `ä»‹ç»æ€§æŒ‡å— "
"<https://jkorpela.fi/unicode/guide.html>`_ ã€‚"

#: ../../howto/unicode.rst:173
msgid ""
"Another `good introductory article "
"<https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-"
"software-developer-absolutely-positively-must-know-about-unicode-and-"
"character-sets-no-excuses/>`_ was written by Joel Spolsky. If this "
"introduction didn't make things clear to you, you should try reading this "
"alternate article before continuing."
msgstr ""
"Joel Spolsky æ’°å†™äº†å¦ä¸€ç¯‡ä¸é”™çš„ä»‹ç»æ€§æ–‡ç«  <https://www.joelonsoftware.com/2003/10/08/the-"
"absolute-minimum-every-software-developer-absolutely-positively-must-know-"
"about-unicode-and-character- set-no-excuses/>`_ "
"ã€‚å¦‚æœæœ¬æ–‡æ²¡è®©æ‚¨å¼„æ¸…æ¥šï¼Œé‚£åº”åœ¨ç»§ç»­ä¹‹å‰å…ˆè¯•ç€è¯»è¯»è¿™ç¯‡æ–‡ç« ã€‚"

#: ../../howto/unicode.rst:178
msgid ""
"Wikipedia entries are often helpful; see the entries for \"`character "
"encoding <https://en.wikipedia.org/wiki/Character_encoding>`_\" and `UTF-8 "
"<https://en.wikipedia.org/wiki/UTF-8>`_, for example."
msgstr ""
"Wikipedia æ¡ç›®é€šå¸¸ä¹Ÿæœ‰å¸®åŠ©ï¼›è¯·å‚é˜…â€œ`å­—ç¬¦ç¼–ç  "
"<https://en.wikipedia.org/wiki/Character_encoding>`_â€å’Œ `UTF-8 "
"<https://en.wikipedia.org/wiki/UTF-8>`_ çš„æ¡ç›®ï¼Œä¾‹å¦‚ï¼š"

#: ../../howto/unicode.rst:184
msgid "Python's Unicode Support"
msgstr "Pythonå¯¹Unicodeçš„æ”¯æŒ"

#: ../../howto/unicode.rst:186
msgid ""
"Now that you've learned the rudiments of Unicode, we can look at Python's "
"Unicode features."
msgstr "ç°åœ¨æ‚¨å·²ç»äº†è§£äº† Unicode çš„åŸºç¡€çŸ¥è¯†ï¼Œå¯ä»¥çœ‹ä¸‹ Python çš„ Unicode ç‰¹æ€§ã€‚"

#: ../../howto/unicode.rst:190
msgid "The String Type"
msgstr "å­—ç¬¦ä¸²ç±»å‹"

#: ../../howto/unicode.rst:192
msgid ""
"Since Python 3.0, the language's :class:`str` type contains Unicode "
"characters, meaning any string created using ``\"unicode rocks!\"``, "
"``'unicode rocks!'``, or the triple-quoted string syntax is stored as "
"Unicode."
msgstr ""
"ä» Python 3.0 å¼€å§‹ï¼Œ :class:`str` ç±»å‹åŒ…å«äº† Unicode å­—ç¬¦ï¼Œè¿™æ„å‘³ç€ç”¨ ``\"unicode "
"rocks!\"``ã€``'unicode rocks!'`` æˆ–ä¸‰é‡å¼•å·å­—ç¬¦ä¸²è¯­æ³•åˆ›å»ºçš„ä»»ä½•å­—ç¬¦ä¸²éƒ½ä¼šå­˜å‚¨ä¸º Unicodeã€‚"

#: ../../howto/unicode.rst:196
msgid ""
"The default encoding for Python source code is UTF-8, so you can simply "
"include a Unicode character in a string literal::"
msgstr "Python æºä»£ç çš„é»˜è®¤ç¼–ç æ˜¯ UTF-8ï¼Œå› æ­¤å¯ä»¥ç›´æ¥åœ¨å­—ç¬¦ä¸²ä¸­åŒ…å« Unicode å­—ç¬¦ï¼š"

#: ../../howto/unicode.rst:199
msgid ""
"try:\n"
"    with open('/tmp/input.txt', 'r') as f:\n"
"        ...\n"
"except OSError:\n"
"    # 'File not found' error message.\n"
"    print(\"Fichier non trouvÃ©\")"
msgstr ""
"try:\n"
"    with open('/tmp/input.txt', 'r') as f:\n"
"        ...\n"
"except OSError:\n"
"    # 'File not found' é”™è¯¯æ¶ˆæ¯ã€‚\n"
"    print(\"Fichier non trouvÃ©\")"

#: ../../howto/unicode.rst:206
msgid ""
"Side note: Python 3 also supports using Unicode characters in identifiers::"
msgstr "æ—æ³¨ï¼šPython 3 è¿˜æ”¯æŒåœ¨æ ‡è¯†ç¬¦ä¸­ä½¿ç”¨ Unicode å­—ç¬¦ï¼š"

#: ../../howto/unicode.rst:208
msgid ""
"rÃ©pertoire = \"/tmp/records.log\"\n"
"with open(rÃ©pertoire, \"w\") as f:\n"
"    f.write(\"test\\n\")"
msgstr ""
"rÃ©pertoire = \"/tmp/records.log\"\n"
"with open(rÃ©pertoire, \"w\") as f:\n"
"    f.write(\"test\\n\")"

#: ../../howto/unicode.rst:212
msgid ""
"If you can't enter a particular character in your editor or want to keep the"
" source code ASCII-only for some reason, you can also use escape sequences "
"in string literals. (Depending on your system, you may see the actual "
"capital-delta glyph instead of a \\u escape.) ::"
msgstr ""
"å¦‚æœæ— æ³•åœ¨ç¼–è¾‘å™¨ä¸­è¾“å…¥æŸä¸ªå­—ç¬¦ï¼Œæˆ–å‡ºäºæŸç§åŸå› æƒ³åªä¿ç•™ ASCII ç¼–ç çš„æºä»£ç ï¼Œåˆ™è¿˜å¯ä»¥åœ¨å­—ç¬¦ä¸²ä¸­ä½¿ç”¨è½¬ä¹‰åºåˆ—ã€‚ï¼ˆæ ¹æ®ç³»ç»Ÿçš„ä¸åŒï¼Œå¯èƒ½ä¼šçœ‹åˆ°çœŸçš„å¤§å†™ "
"Delta å­—ä½“è€Œä¸æ˜¯ \\u è½¬ä¹‰ç¬¦ã€‚ï¼‰ï¼š"

#: ../../howto/unicode.rst:217
msgid ""
">>> \"\\N{GREEK CAPITAL LETTER DELTA}\"  # Using the character name\n"
"'\\u0394'\n"
">>> \"\\u0394\"                          # Using a 16-bit hex value\n"
"'\\u0394'\n"
">>> \"\\U00000394\"                      # Using a 32-bit hex value\n"
"'\\u0394'"
msgstr ""
">>> \"\\N{GREEK CAPITAL LETTER DELTA}\"  # ä½¿ç”¨å­—ç¬¦åç§°\n"
"'\\u0394'\n"
">>> \"\\u0394\"                          # ä½¿ç”¨ 16 æ¯”ç‰¹ä½åå…­è¿›åˆ¶æ•°å€¼\n"
"'\\u0394'\n"
">>> \"\\U00000394\"                      # ä½¿ç”¨ 32 æ¯”ç‰¹ä½åå…­è¿›åˆ¶æ•°å€¼\n"
"'\\u0394'"

#: ../../howto/unicode.rst:224
msgid ""
"In addition, one can create a string using the :func:`~bytes.decode` method "
"of :class:`bytes`.  This method takes an *encoding* argument, such as "
"``UTF-8``, and optionally an *errors* argument."
msgstr ""
"æ­¤å¤–ï¼Œå¯ä»¥ç”¨ :class:`bytes` çš„ :func:`~bytes.decode` æ–¹æ³•åˆ›å»ºä¸€ä¸ªå­—ç¬¦ä¸²ã€‚ è¯¥æ–¹æ³•å¯ä»¥æ¥å— *encoding* "
"å‚æ•°ï¼Œæ¯”å¦‚å¯ä»¥ä¸º ``UTF-8`` ï¼Œä»¥åŠå¯é€‰çš„ *errors* å‚æ•°ã€‚"

#: ../../howto/unicode.rst:228
msgid ""
"The *errors* argument specifies the response when the input string can't be "
"converted according to the encoding's rules.  Legal values for this argument"
" are ``'strict'`` (raise a :exc:`UnicodeDecodeError` exception), "
"``'replace'`` (use ``U+FFFD``, ``REPLACEMENT CHARACTER``), ``'ignore'`` "
"(just leave the character out of the Unicode result), or "
"``'backslashreplace'`` (inserts a ``\\xNN`` escape sequence). The following "
"examples show the differences::"
msgstr ""
"è‹¥æ— æ³•æ ¹æ®ç¼–ç è§„åˆ™å¯¹è¾“å…¥å­—ç¬¦ä¸²è¿›è¡Œç¼–ç ï¼Œ*errors* å‚æ•°æŒ‡å®šäº†å“åº”ç­–ç•¥ã€‚ è¯¥å‚æ•°çš„åˆæ³•å€¼å¯ä»¥æ˜¯ ``'strict'`` (è§¦å‘ "
":exc:`UnicodeDecodeError` å¼‚å¸¸)ã€``'replace'`` (ç”¨ ``U+FFFD``ã€``REPLACEMENT "
"CHARACTER``)ã€``'ignore'`` (åªæ˜¯å°†å­—ç¬¦ä» Unicode ç»“æœä¸­å»æ‰)ï¼Œæˆ– ``'backslashreplace'`` "
"(æ’å…¥ä¸€ä¸ª ``\\xNN`` è½¬ä¹‰åºåˆ—)ã€‚ ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†è¿™äº›ä¸åŒçš„å‚æ•°::"

#: ../../howto/unicode.rst:236
msgid ""
">>> b'\\x80abc'.decode(\"utf-8\", \"strict\")  \n"
"Traceback (most recent call last):\n"
"    ...\n"
"UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0:\n"
"  invalid start byte\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"replace\")\n"
"'\\ufffdabc'\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"backslashreplace\")\n"
"'\\\\x80abc'\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"ignore\")\n"
"'abc'"
msgstr ""
">>> b'\\x80abc'.decode(\"utf-8\", \"strict\")  \n"
"Traceback (most recent call last):\n"
"    ...\n"
"UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0:\n"
"  invalid start byte\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"replace\")\n"
"'\\ufffdabc'\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"backslashreplace\")\n"
"'\\\\x80abc'\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"ignore\")\n"
"'abc'"

#: ../../howto/unicode.rst:248
msgid ""
"Encodings are specified as strings containing the encoding's name.  Python "
"comes with roughly 100 different encodings; see the Python Library Reference"
" at :ref:`standard-encodings` for a list.  Some encodings have multiple "
"names; for example, ``'latin-1'``, ``'iso_8859_1'`` and ``'8859``' are all "
"synonyms for the same encoding."
msgstr ""
"ç¼–ç æ ¼å¼ä»¥åŒ…å«ç¼–ç æ ¼å¼åç§°çš„å­—ç¬¦ä¸²æ¥æŒ‡æ˜ã€‚ Python æœ‰å¤§çº¦ 100 ç§ä¸åŒçš„ç¼–ç æ ¼å¼ï¼›æ¸…å•è¯¦è§ Python åº“å‚è€ƒæ–‡æ¡£ "
":ref:`standard-encodings`ã€‚ ä¸€äº›ç¼–ç æ ¼å¼æœ‰å¤šä¸ªåç§°ï¼Œæ¯”å¦‚ ``'latin-1'``ã€``'iso_8859_1'`` å’Œ "
"``'8859`` éƒ½æ˜¯æŒ‡åŒä¸€ç§ç¼–ç ã€‚"

#: ../../howto/unicode.rst:254
msgid ""
"One-character Unicode strings can also be created with the :func:`chr` "
"built-in function, which takes integers and returns a Unicode string of "
"length 1 that contains the corresponding code point.  The reverse operation "
"is the built-in :func:`ord` function that takes a one-character Unicode "
"string and returns the code point value::"
msgstr ""
"åˆ©ç”¨å†…ç½®å‡½æ•° :func:`chr` è¿˜å¯ä»¥åˆ›å»ºå•å­—ç¬¦çš„ Unicode å­—ç¬¦ä¸²ï¼Œè¯¥å‡½æ•°å¯æ¥å—æ•´æ•°å‚æ•°ï¼Œå¹¶è¿”å›åŒ…å«å¯¹åº”ç ä½çš„é•¿åº¦ä¸º 1 çš„ "
"Unicode å­—ç¬¦ä¸²ã€‚å†…ç½®å‡½æ•° :func:`ord` æ˜¯å…¶é€†æ“ä½œï¼Œå‚æ•°ä¸ºå•ä¸ªå­—ç¬¦çš„ Unicode å­—ç¬¦ä¸²ï¼Œå¹¶è¿”å›ç ä½å€¼ï¼š"

#: ../../howto/unicode.rst:260
msgid ""
">>> chr(57344)\n"
"'\\ue000'\n"
">>> ord('\\ue000')\n"
"57344"
msgstr ""
">>> chr(57344)\n"
"'\\ue000'\n"
">>> ord('\\ue000')\n"
"57344"

#: ../../howto/unicode.rst:266
msgid "Converting to Bytes"
msgstr "è½¬æ¢ä¸ºå­—èŠ‚"

#: ../../howto/unicode.rst:268
msgid ""
"The opposite method of :meth:`bytes.decode` is :meth:`str.encode`, which "
"returns a :class:`bytes` representation of the Unicode string, encoded in "
"the requested *encoding*."
msgstr ""
":meth:`bytes.decode` çš„é€†æ–¹æ³•æ˜¯ :meth:`str.encode` ï¼Œå®ƒä¼šè¿”å› Unicode å­—ç¬¦ä¸²çš„ "
":class:`bytes` å½¢å¼ï¼Œå·²æŒ‰è¦æ±‚çš„ *encoding* è¿›è¡Œäº†ç¼–ç ã€‚"

#: ../../howto/unicode.rst:272
msgid ""
"The *errors* parameter is the same as the parameter of the "
":meth:`~bytes.decode` method but supports a few more possible handlers. As "
"well as ``'strict'``, ``'ignore'``, and ``'replace'`` (which in this case "
"inserts a question mark instead of the unencodable character), there is also"
" ``'xmlcharrefreplace'`` (inserts an XML character reference), "
"``backslashreplace`` (inserts a ``\\uNNNN`` escape sequence) and "
"``namereplace`` (inserts a ``\\N{...}`` escape sequence)."
msgstr ""
"å‚æ•° *errors* çš„æ„ä¹‰ä¸ :meth:`~bytes.decode` æ–¹æ³•ç›¸åŒï¼Œä½†æ”¯æŒæ›´å¤šå¯èƒ½çš„handlerã€‚é™¤äº† ``'strict'`` "
"ã€ ``'ignore'`` å’Œ ``'replace'`` ï¼ˆè¿™æ—¶ä¼šæ’å…¥é—®å·æ›¿æ¢æ‰æ— æ³•ç¼–ç çš„å­—ç¬¦ï¼‰ï¼Œè¿˜æœ‰ "
"``'xmlcharrefreplace'`` ï¼ˆæ’å…¥ä¸€ä¸ª XML å­—ç¬¦å¼•ç”¨ï¼‰ã€ ``backslashreplace`` ï¼ˆæ’å…¥ä¸€ä¸ª "
"``\\uNNNN`` è½¬ä¹‰åºåˆ—ï¼‰å’Œ  ``namereplace`` ï¼ˆæ’å…¥ä¸€ä¸ª ``\\N{...}`` è½¬ä¹‰åºåˆ— ï¼‰ã€‚"

#: ../../howto/unicode.rst:280
msgid "The following example shows the different results::"
msgstr "ä»¥ä¸‹ä¾‹å­æ¼”ç¤ºäº†å„ç§ä¸åŒçš„ç»“æœï¼š"

#: ../../howto/unicode.rst:282
msgid ""
">>> u = chr(40960) + 'abcd' + chr(1972)\n"
">>> u.encode('utf-8')\n"
"b'\\xea\\x80\\x80abcd\\xde\\xb4'\n"
">>> u.encode('ascii')  \n"
"Traceback (most recent call last):\n"
"    ...\n"
"UnicodeEncodeError: 'ascii' codec can't encode character '\\ua000' in\n"
"  position 0: ordinal not in range(128)\n"
">>> u.encode('ascii', 'ignore')\n"
"b'abcd'\n"
">>> u.encode('ascii', 'replace')\n"
"b'?abcd?'\n"
">>> u.encode('ascii', 'xmlcharrefreplace')\n"
"b'&#40960;abcd&#1972;'\n"
">>> u.encode('ascii', 'backslashreplace')\n"
"b'\\\\ua000abcd\\\\u07b4'\n"
">>> u.encode('ascii', 'namereplace')\n"
"b'\\\\N{YI SYLLABLE IT}abcd\\\\u07b4'"
msgstr ""
">>> u = chr(40960) + 'abcd' + chr(1972)\n"
">>> u.encode('utf-8')\n"
"b'\\xea\\x80\\x80abcd\\xde\\xb4'\n"
">>> u.encode('ascii')  \n"
"Traceback (most recent call last):\n"
"    ...\n"
"UnicodeEncodeError: 'ascii' codec can't encode character '\\ua000' in\n"
"  position 0: ordinal not in range(128)\n"
">>> u.encode('ascii', 'ignore')\n"
"b'abcd'\n"
">>> u.encode('ascii', 'replace')\n"
"b'?abcd?'\n"
">>> u.encode('ascii', 'xmlcharrefreplace')\n"
"b'&#40960;abcd&#1972;'\n"
">>> u.encode('ascii', 'backslashreplace')\n"
"b'\\\\ua000abcd\\\\u07b4'\n"
">>> u.encode('ascii', 'namereplace')\n"
"b'\\\\N{YI SYLLABLE IT}abcd\\\\u07b4'"

#: ../../howto/unicode.rst:301
msgid ""
"The low-level routines for registering and accessing the available encodings"
" are found in the :mod:`codecs` module.  Implementing new encodings also "
"requires understanding the :mod:`codecs` module. However, the encoding and "
"decoding functions returned by this module are usually more low-level than "
"is comfortable, and writing new encodings is a specialized task, so the "
"module won't be covered in this HOWTO."
msgstr ""
"ç”¨äºæ³¨å†Œå’Œè®¿é—®å¯ç”¨ç¼–ç æ ¼å¼çš„åº•å±‚å‡½æ•°ï¼Œä½äº :mod:`codecs` æ¨¡å—ä¸­ã€‚ è‹¥è¦å®ç°æ–°çš„ç¼–ç æ ¼å¼ï¼Œåˆ™è¿˜éœ€è¦äº†è§£ :mod:`codecs` æ¨¡å—ã€‚"
" ä¸è¿‡è¯¥æ¨¡å—è¿”å›çš„ç¼–ç å’Œè§£ç å‡½æ•°é€šå¸¸æ›´ä¸ºåº•å±‚ä¸€äº›ï¼Œä¸å¤§å¥½ç”¨ï¼Œç¼–å†™æ–°çš„ç¼–ç æ ¼å¼æ˜¯ä¸€é¡¹ä¸“ä¸šçš„ä»»åŠ¡ï¼Œå› æ­¤æœ¬æ–‡ä¸ä¼šæ¶‰åŠè¯¥æ¨¡å—ã€‚"

#: ../../howto/unicode.rst:310
msgid "Unicode Literals in Python Source Code"
msgstr "Python æºä»£ç ä¸­çš„ Unicode æ–‡å­—"

#: ../../howto/unicode.rst:312
msgid ""
"In Python source code, specific Unicode code points can be written using the"
" ``\\u`` escape sequence, which is followed by four hex digits giving the "
"code point.  The ``\\U`` escape sequence is similar, but expects eight hex "
"digits, not four::"
msgstr ""
"åœ¨ Python æºä»£ç ä¸­ï¼Œå¯ä»¥ç”¨ ``\\u`` è½¬ä¹‰åºåˆ—ä¹¦å†™ç‰¹å®šçš„ Unicode ç ä½ï¼Œè¯¥åºåˆ—åè·Ÿ 4 ä¸ªä»£è¡¨ç ä½çš„åå…­è¿›åˆ¶æ•°å­—ã€‚``\\U`` "
"è½¬ä¹‰åºåˆ—ç”¨æ³•ç±»ä¼¼ï¼Œä½†è¦ç”¨8 ä¸ªåå…­è¿›åˆ¶æ•°å­—ï¼Œè€Œä¸æ˜¯ 4 ä¸ªï¼š"

#: ../../howto/unicode.rst:317
msgid ""
">>> s = \"a\\xac\\u1234\\u20ac\\U00008000\"\n"
"... #     ^^^^ two-digit hex escape\n"
"... #         ^^^^^^ four-digit Unicode escape\n"
"... #                     ^^^^^^^^^^ eight-digit Unicode escape\n"
">>> [ord(c) for c in s]\n"
"[97, 172, 4660, 8364, 32768]"
msgstr ""
">>> s = \"a\\xac\\u1234\\u20ac\\U00008000\"\n"
"... #     ^^^^ ä¸¤ä½åå…­è¿›åˆ¶æ•°è½¬ä¹‰\n"
"... #         ^^^^^^ å››ä½ Unicode è½¬ä¹‰\n"
"... #                     ^^^^^^^^^^ å…«ä½ Unicode è½¬ä¹‰\n"
">>> [ord(c) for c in s]\n"
"[97, 172, 4660, 8364, 32768]"

#: ../../howto/unicode.rst:324
msgid ""
"Using escape sequences for code points greater than 127 is fine in small "
"doses, but becomes an annoyance if you're using many accented characters, as"
" you would in a program with messages in French or some other accent-using "
"language.  You can also assemble strings using the :func:`chr` built-in "
"function, but this is even more tedious."
msgstr ""
"å¯¹å¤§äº 127 "
"çš„ç ä½ä½¿ç”¨è½¬ä¹‰åºåˆ—ï¼Œæ•°é‡ä¸å¤šæ—¶æ²¡ä»€ä¹ˆé—®é¢˜ï¼Œä½†å¦‚æœè¦ç”¨åˆ°å¾ˆå¤šé‡éŸ³å­—ç¬¦ï¼Œè¿™ä¼šå˜å¾—å¾ˆçƒ¦äººï¼Œç±»ä¼¼äºç¨‹åºä¸­çš„ä¿¡æ¯æ˜¯ç”¨æ³•è¯­æˆ–å…¶ä»–ä½¿ç”¨é‡éŸ³çš„è¯­è¨€å†™çš„ã€‚ä¹Ÿå¯ä»¥ç”¨å†…ç½®å‡½æ•°"
" :func:`chr` æ‹¼è£…å­—ç¬¦ä¸²ï¼Œä½†ä¼šæ›´åŠ ä¹å‘³ã€‚"

#: ../../howto/unicode.rst:330
msgid ""
"Ideally, you'd want to be able to write literals in your language's natural "
"encoding.  You could then edit Python source code with your favorite editor "
"which would display the accented characters naturally, and have the right "
"characters used at runtime."
msgstr ""
"ç†æƒ³æƒ…å†µä¸‹ï¼Œéƒ½å¸Œæœ›èƒ½ç”¨æ¯è¯­çš„ç¼–ç ä¹¦å†™æ–‡æœ¬ã€‚è¿˜èƒ½ç”¨å–œå¥½çš„ç¼–è¾‘å™¨ç¼–è¾‘ Python æºä»£ç ï¼Œç¼–è¾‘å™¨è¦èƒ½è‡ªç„¶åœ°æ˜¾ç¤ºé‡éŸ³ç¬¦ï¼Œå¹¶åœ¨è¿è¡Œæ—¶ä½¿ç”¨æ­£ç¡®çš„å­—ç¬¦ã€‚"

#: ../../howto/unicode.rst:335
msgid ""
"Python supports writing source code in UTF-8 by default, but you can use "
"almost any encoding if you declare the encoding being used.  This is done by"
" including a special comment as either the first or second line of the "
"source file::"
msgstr ""
"é»˜è®¤æƒ…å†µä¸‹ï¼ŒPython æ”¯æŒä»¥ UTF-8 "
"æ ¼å¼ç¼–å†™æºä»£ç ï¼Œä½†å¦‚æœå£°æ˜è¦ç”¨çš„ç¼–ç ï¼Œåˆ™å‡ ä¹å¯ä»¥ä½¿ç”¨ä»»ä½•ç¼–ç ã€‚åªè¦åœ¨æºæ–‡ä»¶çš„ç¬¬ä¸€è¡Œæˆ–ç¬¬äºŒè¡ŒåŒ…å«ä¸€ä¸ªç‰¹æ®Šæ³¨é‡Šå³å¯ï¼š"

#: ../../howto/unicode.rst:339
msgid ""
"#!/usr/bin/env python\n"
"# -*- coding: latin-1 -*-\n"
"\n"
"u = 'abcdÃ©'\n"
"print(ord(u[-1]))"
msgstr ""
"#!/usr/bin/env python\n"
"# -*- coding: latin-1 -*-\n"
"\n"
"u = 'abcdÃ©'\n"
"print(ord(u[-1]))"

#: ../../howto/unicode.rst:345
msgid ""
"The syntax is inspired by Emacs's notation for specifying variables local to"
" a file.  Emacs supports many different variables, but Python only supports "
"'coding'.  The ``-*-`` symbols indicate to Emacs that the comment is "
"special; they have no significance to Python but are a convention.  Python "
"looks for ``coding: name`` or ``coding=name`` in the comment."
msgstr ""
"ä¸Šè¿°è¯­æ³•çš„çµæ„Ÿæ¥è‡ªäº Emacs ç”¨äºæŒ‡å®šæ–‡ä»¶å±€éƒ¨å˜é‡çš„ç¬¦å·ã€‚Emacs æ”¯æŒè®¸å¤šä¸åŒçš„å˜é‡ï¼Œä½† Python ä»…æ”¯æŒâ€œç¼–ç â€ã€‚ ``-*-`` ç¬¦å·å‘"
" Emacs æ ‡æ˜è¯¥æ³¨é‡Šæ˜¯ç‰¹æ®Šçš„ï¼›è¿™å¯¹ Python æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ï¼Œåªæ˜¯ä¸€ç§çº¦å®šã€‚Python ä¼šåœ¨æ³¨é‡Šä¸­æŸ¥æ‰¾ ``coding: name`` æˆ– "
"``coding=name`` ã€‚"

#: ../../howto/unicode.rst:351
msgid ""
"If you don't include such a comment, the default encoding used will be UTF-8"
" as already mentioned.  See also :pep:`263` for more information."
msgstr "å¦‚æœæ²¡æœ‰è¿™ç§æ³¨é‡Šï¼Œåˆ™é»˜è®¤ç¼–ç å°†ä¼šæ˜¯å‰é¢æåˆ°çš„ UTF-8ã€‚æ›´å¤šä¿¡æ¯è¯·å‚é˜… :pep:`263` ã€‚"

#: ../../howto/unicode.rst:356
msgid "Unicode Properties"
msgstr "Unicodeå±æ€§"

#: ../../howto/unicode.rst:358
msgid ""
"The Unicode specification includes a database of information about code "
"points.  For each defined code point, the information includes the "
"character's name, its category, the numeric value if applicable (for "
"characters representing numeric concepts such as the Roman numerals, "
"fractions such as one-third and four-fifths, etc.).  There are also display-"
"related properties, such as how to use the code point in bidirectional text."
msgstr ""
"Unicode "
"è§„èŒƒåŒ…å«äº†ä¸€ä¸ªç ä½ä¿¡æ¯æ•°æ®åº“ã€‚å¯¹äºå®šä¹‰çš„æ¯ä¸€ä¸ªç ä½ï¼Œéƒ½åŒ…å«äº†å­—ç¬¦çš„åç§°ã€ç±»åˆ«ã€æ•°å€¼ï¼ˆå¯¹äºè¡¨ç¤ºæ•°å­—æ¦‚å¿µçš„å­—ç¬¦ï¼Œå¦‚ç½—é©¬æ•°å­—ã€åˆ†æ•°å¦‚ä¸‰åˆ†ä¹‹ä¸€å’Œäº”åˆ†ä¹‹å››ç­‰ï¼‰ã€‚è¿˜æœ‰æœ‰å…³æ˜¾ç¤ºçš„å±æ€§ï¼Œæ¯”å¦‚å¦‚ä½•åœ¨åŒå‘æ–‡æœ¬ä¸­ä½¿ç”¨ç ä½ã€‚"

#: ../../howto/unicode.rst:366
msgid ""
"The following program displays some information about several characters, "
"and prints the numeric value of one particular character::"
msgstr "ä»¥ä¸‹ç¨‹åºæ˜¾ç¤ºäº†å‡ ä¸ªå­—ç¬¦çš„ä¿¡æ¯ï¼Œå¹¶æ‰“å°ä¸€ä¸ªå­—ç¬¦çš„æ•°å€¼ï¼š"

#: ../../howto/unicode.rst:369
msgid ""
"import unicodedata\n"
"\n"
"u = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)\n"
"\n"
"for i, c in enumerate(u):\n"
"    print(i, '%04x' % ord(c), unicodedata.category(c), end=\" \")\n"
"    print(unicodedata.name(c))\n"
"\n"
"# Get numeric value of second character\n"
"print(unicodedata.numeric(u[1]))"
msgstr ""
"import unicodedata\n"
"\n"
"u = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)\n"
"\n"
"for i, c in enumerate(u):\n"
"    print(i, '%04x' % ord(c), unicodedata.category(c), end=\" \")\n"
"    print(unicodedata.name(c))\n"
"\n"
"# è·å–ç¬¬äºŒä¸ªå­—ç¬¦çš„æ•°å€¼\n"
"print(unicodedata.numeric(u[1]))"

#: ../../howto/unicode.rst:380
msgid "When run, this prints:"
msgstr "å½“è¿è¡Œæ—¶ï¼Œè¿™å°†æ‰“å°å‡ºï¼š"

#: ../../howto/unicode.rst:382
msgid ""
"0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE\n"
"1 0bf2 No TAMIL NUMBER ONE THOUSAND\n"
"2 0f84 Mn TIBETAN MARK HALANTA\n"
"3 1770 Lo TAGBANWA LETTER SA\n"
"4 33af So SQUARE RAD OVER S SQUARED\n"
"1000.0"
msgstr ""
"0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE\n"
"1 0bf2 No TAMIL NUMBER ONE THOUSAND\n"
"2 0f84 Mn TIBETAN MARK HALANTA\n"
"3 1770 Lo TAGBANWA LETTER SA\n"
"4 33af So SQUARE RAD OVER S SQUARED\n"
"1000.0"

#: ../../howto/unicode.rst:391
msgid ""
"The category codes are abbreviations describing the nature of the character."
" These are grouped into categories such as \"Letter\", \"Number\", "
"\"Punctuation\", or \"Symbol\", which in turn are broken up into "
"subcategories.  To take the codes from the above output, ``'Ll'`` means "
"'Letter, lowercase', ``'No'`` means \"Number, other\", ``'Mn'`` is \"Mark, "
"nonspacing\", and ``'So'`` is \"Symbol, other\".  See `the General Category "
"Values section of the Unicode Character Database documentation "
"<https://www.unicode.org/reports/tr44/#General_Category_Values>`_ for a list"
" of category codes."
msgstr ""
"ç±»åˆ«ä»£ç æ˜¯æè¿°å­—ç¬¦æ€§è´¨çš„ä¸€ä¸ªç¼©å†™ã€‚åˆ†ä¸ºâ€œå­—æ¯â€ã€â€œæ•°å­—â€ã€â€œæ ‡ç‚¹ç¬¦å·â€æˆ–â€œç¬¦å·â€ç­‰ç±»åˆ«ï¼Œè€Œè¿™äº›ç±»åˆ«åˆåˆ†ä¸ºå­ç±»åˆ«ã€‚å°±ä»¥ä¸Šè¾“å‡ºçš„ä»£ç è€Œè¨€ï¼Œ``'Ll'`` "
"è¡¨ç¤ºâ€œå­—æ¯ï¼Œå°å†™â€ï¼Œ``'No'`` è¡¨ç¤ºâ€œæ•°å­—ï¼Œå…¶ä»–â€ï¼Œ``'Mn'`` è¡¨ç¤ºâ€œæ ‡è®°ï¼Œéç©ºç™½ç¬¦â€ ,  ``'So'`` "
"æ˜¯â€œç¬¦å·ï¼Œå…¶ä»–â€ã€‚æœ‰å…³ç±»åˆ«ä»£ç çš„æ¸…å•ï¼Œè¯·å‚é˜… `Unicode å­—ç¬¦åº“æ–‡æ¡£ "
"<https://www.unicode.org/reports/tr44/#General_Category_Values>`_ "
"çš„â€œé€šç”¨ç±»åˆ«å€¼â€éƒ¨åˆ†ã€‚"

#: ../../howto/unicode.rst:402
msgid "Comparing Strings"
msgstr "å­—ç¬¦ä¸²æ¯”è¾ƒ"

#: ../../howto/unicode.rst:404
msgid ""
"Unicode adds some complication to comparing strings, because the same set of"
" characters can be represented by different sequences of code points.  For "
"example, a letter like 'Ãª' can be represented as a single code point U+00EA,"
" or as U+0065 U+0302, which is the code point for 'e' followed by a code "
"point for 'COMBINING CIRCUMFLEX ACCENT'.  These will produce the same output"
" when printed, but one is a string of length 1 and the other is of length 2."
msgstr ""
"Unicode è®©å­—ç¬¦ä¸²çš„æ¯”è¾ƒå˜å¾—å¤æ‚äº†ä¸€äº›ï¼Œå› ä¸ºåŒä¸€ç»„å­—ç¬¦å¯èƒ½ç”±ä¸åŒçš„ç ä½åºåˆ—ç»„æˆã€‚ä¾‹å¦‚ï¼Œåƒâ€œÃªâ€è¿™æ ·çš„å­—æ¯å¯ä»¥è¡¨ç¤ºä¸ºå•ç ä½ U+00EAï¼Œæˆ–æ˜¯ "
"U+0065 U+0302ï¼Œå³â€œeâ€çš„ç ä½åè·Ÿâ€œCOMBINING CIRCUMFLEX "
"ACCENTâ€çš„ç ä½ã€‚è™½ç„¶åœ¨æ‰“å°æ—¶ä¼šäº§ç”ŸåŒæ ·çš„è¾“å‡ºï¼Œä½†ä¸€ä¸ªæ˜¯é•¿åº¦ä¸º 1 çš„å­—ç¬¦ä¸²ï¼Œå¦ä¸€ä¸ªæ˜¯é•¿åº¦ä¸º 2 çš„å­—ç¬¦ä¸²ã€‚"

#: ../../howto/unicode.rst:412
msgid ""
"One tool for a case-insensitive comparison is the :meth:`~str.casefold` "
"string method that converts a string to a case-insensitive form following an"
" algorithm described by the Unicode Standard.  This algorithm has special "
"handling for characters such as the German letter 'ÃŸ' (code point U+00DF), "
"which becomes the pair of lowercase letters 'ss'."
msgstr ""
"ä¸€ç§ä¸åŒºåˆ†å¤§å°å†™æ¯”è¾ƒçš„å·¥å…·æ˜¯å­—ç¬¦ä¸²æ–¹æ³• :meth:`~str.casefold` ï¼Œå°†æŒ‰ç…§ Unicode "
"æ ‡å‡†æè¿°çš„ç®—æ³•å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºä¸åŒºåˆ†å¤§å°å†™çš„å½¢å¼ã€‚è¯¥ç®—æ³•å¯¹è¯¸å¦‚å¾·è¯­å­—æ¯â€œÃŸâ€ï¼ˆä»£ç ç‚¹ U+00DFï¼‰ä¹‹ç±»çš„å­—ç¬¦è¿›è¡Œäº†ç‰¹æ®Šå¤„ç†ï¼Œå˜ä¸ºä¸€å¯¹å°å†™å­—æ¯â€œssâ€ã€‚"

#: ../../howto/unicode.rst:421
msgid ""
">>> street = 'GÃ¼rzenichstraÃŸe'\n"
">>> street.casefold()\n"
"'gÃ¼rzenichstrasse'"
msgstr ""
">>> street = 'GÃ¼rzenichstraÃŸe'\n"
">>> street.casefold()\n"
"'gÃ¼rzenichstrasse'"

#: ../../howto/unicode.rst:425
msgid ""
"A second tool is the :mod:`unicodedata` module's "
":func:`~unicodedata.normalize` function that converts strings to one of "
"several normal forms, where letters followed by a combining character are "
"replaced with single characters.  :func:`~unicodedata.normalize` can be used"
" to perform string comparisons that won't falsely report inequality if two "
"strings use combining characters differently:"
msgstr ""
"ç¬¬äºŒä¸ªå·¥å…·æ˜¯ :mod:`unicodedata` æ¨¡å—çš„ :func:`~unicodedata.normalize` "
"å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå‡ ç§è§„èŒƒåŒ–å½¢å¼ä¹‹ä¸€ï¼Œå³ç”¨å•å­—ç¬¦æ›¿æ¢åé¢å¸¦ä¸€ä¸ªç»„åˆå­—ç¬¦çš„å¤šä¸ªå­—æ¯ã€‚ "
":func:`~unicodedata.normalize` å¯è¢«ç”¨äºæ‰§è¡Œå­—ç¬¦ä¸²æ¯”è¾ƒï¼Œå¦‚æœä¸¤ä¸ªå­—ç¬¦ä¸²ä½¿ç”¨ä¸åŒçš„ç»„åˆå­—ç¬¦ï¼Œä¹Ÿä¸ä¼šé”™è¯¯åœ°æŠ¥å‘Šä¸¤è€…ä¸ç›¸ç­‰:"

#: ../../howto/unicode.rst:434
msgid ""
"import unicodedata\n"
"\n"
"def compare_strs(s1, s2):\n"
"    def NFD(s):\n"
"        return unicodedata.normalize('NFD', s)\n"
"\n"
"    return NFD(s1) == NFD(s2)\n"
"\n"
"single_char = 'Ãª'\n"
"multiple_chars = '\\N{LATIN SMALL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\n"
"print('length of first string=', len(single_char))\n"
"print('length of second string=', len(multiple_chars))\n"
"print(compare_strs(single_char, multiple_chars))"
msgstr ""
"import unicodedata\n"
"\n"
"def compare_strs(s1, s2):\n"
"    def NFD(s):\n"
"        return unicodedata.normalize('NFD', s)\n"
"\n"
"    return NFD(s1) == NFD(s2)\n"
"\n"
"single_char = 'Ãª'\n"
"multiple_chars = '\\N{LATIN SMALL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\n"
"print('length of first string=', len(single_char))\n"
"print('length of second string=', len(multiple_chars))\n"
"print(compare_strs(single_char, multiple_chars))"

#: ../../howto/unicode.rst:448
msgid "When run, this outputs:"
msgstr "å½“è¿è¡Œæ—¶ï¼Œè¿™å°†è¾“å‡ºï¼š"

#: ../../howto/unicode.rst:450
msgid ""
"$ python compare-strs.py\n"
"length of first string= 1\n"
"length of second string= 2\n"
"True"
msgstr ""
"$ python compare-strs.py\n"
"length of first string= 1\n"
"length of second string= 2\n"
"True"

#: ../../howto/unicode.rst:457
msgid ""
"The first argument to the :func:`~unicodedata.normalize` function is a "
"string giving the desired normalization form, which can be one of 'NFC', "
"'NFKC', 'NFD', and 'NFKD'."
msgstr ""
":func:`~unicodedata.normalize` "
"å‡½æ•°çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ä¸ªå­—ç¬¦ä¸²ï¼Œç»™å‡ºæ‰€éœ€çš„è§„èŒƒåŒ–å½¢å¼ï¼Œå¯ä»¥æ˜¯â€œNFCâ€ã€â€œNFKCâ€ã€â€œNFDâ€å’Œâ€œNFKDâ€ä¹‹ä¸€ã€‚"

#: ../../howto/unicode.rst:461
msgid "The Unicode Standard also specifies how to do caseless comparisons::"
msgstr "Unicode æ ‡å‡†è¿˜è®¾å®šäº†å¦‚ä½•è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„æ¯”è¾ƒï¼š"

#: ../../howto/unicode.rst:463
msgid ""
"import unicodedata\n"
"\n"
"def compare_caseless(s1, s2):\n"
"    def NFD(s):\n"
"        return unicodedata.normalize('NFD', s)\n"
"\n"
"    return NFD(NFD(s1).casefold()) == NFD(NFD(s2).casefold())\n"
"\n"
"# Example usage\n"
"single_char = 'Ãª'\n"
"multiple_chars = '\\N{LATIN CAPITAL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\n"
"\n"
"print(compare_caseless(single_char, multiple_chars))"
msgstr ""
"import unicodedata\n"
"\n"
"def compare_caseless(s1, s2):\n"
"    def NFD(s):\n"
"        return unicodedata.normalize('NFD', s)\n"
"\n"
"    return NFD(NFD(s1).casefold()) == NFD(NFD(s2).casefold())\n"
"\n"
"# ä½¿ç”¨ç¤ºä¾‹\n"
"single_char = 'Ãª'\n"
"multiple_chars = '\\N{LATIN CAPITAL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}'\n"
"\n"
"print(compare_caseless(single_char, multiple_chars))"

#: ../../howto/unicode.rst:477
msgid ""
"This will print ``True``.  (Why is :func:`!NFD` invoked twice?  Because "
"there are a few characters that make :meth:`~str.casefold` return a non-"
"normalized string, so the result needs to be normalized again. See section "
"3.13 of the Unicode Standard for a discussion and an example.)"
msgstr ""
"è¿™å°†æ‰“å° ``True``ã€‚ ï¼ˆä¸ºä»€ä¹ˆ :func:`!NFD` ä¼šä¸¤æ¬¡è¢«å‘èµ·è°ƒç”¨ï¼Ÿå› ä¸ºæœ‰å‡ ä¸ªå­—ç¬¦ä¼šä½¿ :meth:`~str.casefold` "
"è¿”å›éè§„èŒƒåŒ–çš„å­—ç¬¦ä¸²ï¼Œæ‰€ä»¥éœ€è¦å†æ¬¡å¯¹ç»“æœè¿›è¡Œè§„èŒƒåŒ–å¤„ç†ã€‚ æœ‰å…³è®¨è®ºå’Œç¤ºä¾‹ï¼Œè¯·å‚é˜… Unicode æ ‡å‡†ç¬¬ 3.13 èŠ‚ï¼‰ã€‚"

#: ../../howto/unicode.rst:484
msgid "Unicode Regular Expressions"
msgstr "Unicode æ­£åˆ™è¡¨è¾¾å¼"

#: ../../howto/unicode.rst:486
msgid ""
"The regular expressions supported by the :mod:`re` module can be provided "
"either as bytes or strings.  Some of the special character sequences such as"
" ``\\d`` and ``\\w`` have different meanings depending on whether the "
"pattern is supplied as bytes or a string.  For example, ``\\d`` will match "
"the characters ``[0-9]`` in bytes but in strings will match any character "
"that's in the ``'Nd'`` category."
msgstr ""
":mod:`re` æ¨¡å—æ”¯æŒçš„æ­£åˆ™è¡¨è¾¾å¼å¯ä»¥ç”¨å­—èŠ‚ä¸²æˆ–å­—ç¬¦ä¸²çš„å½¢å¼æä¾›ã€‚æœ‰ä¸€äº›ç‰¹æ®Šå­—ç¬¦åºåˆ—ï¼Œæ¯”å¦‚ ``\\d`` å’Œ ``\\w`` "
"å…·æœ‰ä¸åŒçš„å«ä¹‰ï¼Œå…·ä½“å–å†³äºåŒ¹é…æ¨¡å¼æ˜¯ä»¥å­—èŠ‚ä¸²è¿˜æ˜¯å­—ç¬¦ä¸²å½¢å¼æä¾›çš„ã€‚ä¾‹å¦‚ï¼Œ``\\d`` å°†åŒ¹é…å­—èŠ‚ä¸²ä¸­çš„å­—ç¬¦ ``[0-9]`` ï¼Œä½†å¯¹äºå­—ç¬¦ä¸²å°†ä¼šåŒ¹é…"
" ``'Nd'`` ç±»åˆ«ä¸­çš„ä»»ä½•å­—ç¬¦ã€‚"

#: ../../howto/unicode.rst:493
msgid ""
"The string in this example has the number 57 written in both Thai and Arabic"
" numerals::"
msgstr "ä¸Šè¿°ç¤ºä¾‹ä¸­çš„å­—ç¬¦ä¸²åŒ…å«äº†æ³°è¯­å’Œé˜¿æ‹‰ä¼¯æ•°å­—ä¹¦å†™çš„æ•°å­— 57ï¼š"

#: ../../howto/unicode.rst:496
msgid ""
"import re\n"
"p = re.compile(r'\\d+')\n"
"\n"
"s = \"Over \\u0e55\\u0e57 57 flavours\"\n"
"m = p.search(s)\n"
"print(repr(m.group()))"
msgstr ""
"import re\n"
"p = re.compile(r'\\d+')\n"
"\n"
"s = \"Over \\u0e55\\u0e57 57 flavours\"\n"
"m = p.search(s)\n"
"print(repr(m.group()))"

#: ../../howto/unicode.rst:503
msgid ""
"When executed, ``\\d+`` will match the Thai numerals and print them out.  If"
" you supply the :const:`re.ASCII` flag to :func:`~re.compile`, ``\\d+`` will"
" match the substring \"57\" instead."
msgstr ""
"æ‰§è¡Œæ—¶ï¼Œ``\\d+`` å°†åŒ¹é…ä¸Šæ³°è¯­æ•°å­—å¹¶æ‰“å°å‡ºæ¥ã€‚å¦‚æœå‘  :func:`~re.compile` æä¾›çš„æ˜¯ :const:`re.ASCII` "
"æ ‡å¿—ï¼Œ``\\d+`` åˆ™ä¼šåŒ¹é…å­ä¸² \"57\"ã€‚"

#: ../../howto/unicode.rst:507
msgid ""
"Similarly, ``\\w`` matches a wide variety of Unicode characters but only "
"``[a-zA-Z0-9_]`` in bytes or if :const:`re.ASCII` is supplied, and ``\\s`` "
"will match either Unicode whitespace characters or ``[ \\t\\n\\r\\f\\v]``."
msgstr ""
"ç±»ä¼¼åœ°ï¼Œ``\\w`` å°†åŒ¹é…å¤šç§ Unicode å­—ç¬¦ï¼Œä½†å¯¹äºå­—èŠ‚ä¸²åˆ™åªä¼šåŒ¹é… ``[a-zA-Z0-9_]`` ï¼Œå¦‚æœæŒ‡å®š "
":const:`re.ASCII` ï¼Œ ``\\s`` å°†åŒ¹é… Unicode ç©ºç™½ç¬¦æˆ– ``[ \\t\\n\\r\\f\\v]`` ã€‚"

#: ../../howto/unicode.rst:518
msgid "Some good alternative discussions of Python's Unicode support are:"
msgstr "å…³äº Python çš„ Unicode æ”¯æŒï¼Œå…¶ä»–è¿˜æœ‰ä¸€äº›å¾ˆå¥½çš„è®¨è®ºï¼š"

#: ../../howto/unicode.rst:520
msgid ""
"`Processing Text Files in Python 3 <https://python-"
"notes.curiousefficiency.org/en/latest/python3/text_file_processing.html>`_, "
"by Nick Coghlan."
msgstr ""
"`ç”¨ Python 3 å¤„ç†æ–‡æœ¬æ–‡ä»¶ <https://python-"
"notes.curiousefficiency.org/en/latest/python3/text_file_processing.html>`_ "
"ï¼Œä½œè€… Nick Coghlanã€‚"

#: ../../howto/unicode.rst:521
msgid ""
"`Pragmatic Unicode <https://nedbatchelder.com/text/unipain.html>`_, a PyCon "
"2012 presentation by Ned Batchelder."
msgstr ""
"`å®ç”¨çš„ Unicode <https://nedbatchelder.com/text/unipain.html>`_ï¼ŒNed Batchelder "
"åœ¨ PyCon 2012 ä¸Šçš„æ¼”ç¤ºã€‚"

#: ../../howto/unicode.rst:523
msgid ""
"The :class:`str` type is described in the Python library reference at "
":ref:`textseq`."
msgstr ":class:`str` ç±»å‹åœ¨ Python åº“å‚è€ƒæ–‡æ¡£ :ref:`textseq` ä¸­æœ‰ä»‹ç»ã€‚"

#: ../../howto/unicode.rst:526
msgid "The documentation for the :mod:`unicodedata` module."
msgstr ":mod:`unicodedata` æ¨¡å—çš„æ–‡æ¡£"

#: ../../howto/unicode.rst:528
msgid "The documentation for the :mod:`codecs` module."
msgstr ":mod:`codecs` æ¨¡å—çš„æ–‡æ¡£"

#: ../../howto/unicode.rst:530
msgid ""
"Marc-AndrÃ© Lemburg gave `a presentation titled \"Python and Unicode\" (PDF "
"slides) <https://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf>`_ at "
"EuroPython 2002.  The slides are an excellent overview of the design of "
"Python 2's Unicode features (where the Unicode string type is called "
"``unicode`` and literals start with ``u``)."
msgstr ""
"Marc-AndrÃ© Lemburg åœ¨ EuroPython 2002 ä¸Šåšäº†ä¸€ä¸ªé¢˜ä¸ºâ€œPython å’Œ Unicodeâ€ï¼ˆPDF "
"å¹»ç¯ç‰‡ï¼‰<https://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf>`_ "
"çš„æ¼”ç¤ºæ–‡ç¨¿ã€‚è¯¥å¹»ç¯ç‰‡å¾ˆå¥½åœ°æ¦‚æ‹¬äº† Python 2 çš„ Unicode åŠŸèƒ½è®¾è®¡ï¼ˆå…¶ä¸­ Unicode å­—ç¬¦ä¸²ç±»å‹ç§°ä¸º ``unicode``ï¼Œæ–‡å­—ä»¥ "
"``u`` å¼€å¤´ï¼‰ã€‚"

#: ../../howto/unicode.rst:538
msgid "Reading and Writing Unicode Data"
msgstr "Unicode æ•°æ®çš„è¯»å†™"

#: ../../howto/unicode.rst:540
msgid ""
"Once you've written some code that works with Unicode data, the next problem"
" is input/output.  How do you get Unicode strings into your program, and how"
" do you convert Unicode into a form suitable for storage or transmission?"
msgstr ""
"æ—¢ç„¶å¤„ç† Unicode æ•°æ®çš„ä»£ç å†™å¥½äº†ï¼Œä¸‹ä¸€ä¸ªé—®é¢˜å°±æ˜¯è¾“å…¥/è¾“å‡ºäº†ã€‚å¦‚ä½•å°† Unicode å­—ç¬¦ä¸²è¯»å…¥ç¨‹åºï¼Œå¦‚ä½•å°† Unicode "
"è½¬æ¢ä¸ºé€‚äºå­˜å‚¨æˆ–ä¼ è¾“çš„å½¢å¼å‘¢ï¼Ÿ"

#: ../../howto/unicode.rst:544
msgid ""
"It's possible that you may not need to do anything depending on your input "
"sources and output destinations; you should check whether the libraries used"
" in your application support Unicode natively.  XML parsers often return "
"Unicode data, for example.  Many relational databases also support Unicode-"
"valued columns and can return Unicode values from an SQL query."
msgstr ""
"æ ¹æ®è¾“å…¥æºå’Œè¾“å‡ºç›®æ ‡çš„ä¸åŒï¼Œæˆ–è®¸ä»€ä¹ˆéƒ½ä¸ç”¨å¹²ï¼›è¯·æ£€æŸ¥ä¸€ä¸‹åº”ç”¨ç¨‹åºç”¨åˆ°çš„åº“æ˜¯å¦åŸç”Ÿæ”¯æŒ Unicodeã€‚ä¾‹å¦‚ï¼ŒXML è§£æå™¨å¾€å¾€ä¼šè¿”å› Unicode "
"æ•°æ®ã€‚è®¸å¤šå…³ç³»æ•°æ®åº“çš„å­—æ®µä¹Ÿæ”¯æŒ Unicode å€¼ï¼Œå¹¶ä¸” SQL æŸ¥è¯¢ä¹Ÿèƒ½è¿”å› Unicode å€¼ã€‚"

#: ../../howto/unicode.rst:550
msgid ""
"Unicode data is usually converted to a particular encoding before it gets "
"written to disk or sent over a socket.  It's possible to do all the work "
"yourself: open a file, read an 8-bit bytes object from it, and convert the "
"bytes with ``bytes.decode(encoding)``.  However, the manual approach is not "
"recommended."
msgstr ""
"åœ¨å†™å…¥ç£ç›˜æˆ–é€šè¿‡å¥—æ¥å­—å‘é€ä¹‹å‰ï¼ŒUnicode æ•°æ®é€šå¸¸è¦è½¬æ¢ä¸ºç‰¹å®šçš„ç¼–ç ã€‚å¯ä»¥è‡ªå·±å®Œæˆæ‰€æœ‰å·¥ä½œï¼šæ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ï¼Œä»ä¸­è¯»å–ä¸€ä¸ª 8 ä½å­—èŠ‚å¯¹è±¡ï¼Œç„¶åç”¨ "
"``bytes.decode(encoding)`` å¯¹å­—èŠ‚ä¸²è¿›è¡Œè½¬æ¢ã€‚ä½†æ˜¯ï¼Œä¸æ¨èé‡‡ç”¨è¿™ç§å…¨äººå·¥çš„æ–¹æ¡ˆã€‚"

#: ../../howto/unicode.rst:555
msgid ""
"One problem is the multi-byte nature of encodings; one Unicode character can"
" be represented by several bytes.  If you want to read the file in "
"arbitrary-sized chunks (say, 1024 or 4096 bytes), you need to write error-"
"handling code to catch the case where only part of the bytes encoding a "
"single Unicode character are read at the end of a chunk.  One solution would"
" be to read the entire file into memory and then perform the decoding, but "
"that prevents you from working with files that are extremely large; if you "
"need to read a 2 GiB file, you need 2 GiB of RAM. (More, really, since for "
"at least a moment you'd need to have both the encoded string and its Unicode"
" version in memory.)"
msgstr ""
"ç¼–ç çš„å¤šå­—èŠ‚ç‰¹æ€§å°±æ˜¯ä¸€ä¸ªéš¾é¢˜ï¼› ä¸€ä¸ª Unicode å­—ç¬¦å¯ä»¥ç”¨å‡ ä¸ªå­—èŠ‚è¡¨ç¤ºã€‚ å¦‚æœè¦ä»¥ä»»æ„å¤§å°çš„å—ï¼ˆä¾‹å¦‚ 1024 æˆ– 4096 "
"å­—èŠ‚ï¼‰è¯»å–æ–‡ä»¶ï¼Œé‚£ä¹ˆåœ¨å—çš„æœ«å°¾å¯èƒ½åªè¯»åˆ°æŸä¸ª Unicode å­—ç¬¦çš„éƒ¨åˆ†å­—èŠ‚ï¼Œè¿™å°±éœ€è¦ç¼–å†™é”™è¯¯å¤„ç†ä»£ç ã€‚ "
"æœ‰ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯å°†æ•´ä¸ªæ–‡ä»¶è¯»å…¥å†…å­˜ï¼Œç„¶åè¿›è¡Œè§£ç ï¼Œä½†è¿™æ ·å°±æ²¡æ³•å¤„ç†å¾ˆå¤§çš„æ–‡ä»¶äº†ï¼›è‹¥è¦è¯»å– 2 GB çš„æ–‡ä»¶ï¼Œå°±éœ€è¦ 2 GB çš„ "
"RAMã€‚ï¼ˆå…¶å®éœ€è¦çš„å†…å­˜ä¼šæ›´å¤šäº›ï¼Œå› ä¸ºè‡³å°‘æœ‰ä¸€æ®µæ—¶é—´éœ€è¦åœ¨å†…å­˜ä¸­åŒæ—¶å­˜æ”¾å·²ç¼–ç å­—ç¬¦ä¸²åŠå…¶ Unicode ç‰ˆæœ¬ã€‚ï¼‰"

#: ../../howto/unicode.rst:565
msgid ""
"The solution would be to use the low-level decoding interface to catch the "
"case of partial coding sequences.  The work of implementing this has already"
" been done for you: the built-in :func:`open` function can return a file-"
"like object that assumes the file's contents are in a specified encoding and"
" accepts Unicode parameters for methods such as :meth:`~io.TextIOBase.read` "
"and :meth:`~io.TextIOBase.write`.  This works through :func:`open`\\'s "
"*encoding* and *errors* parameters which are interpreted just like those in "
":meth:`str.encode` and :meth:`bytes.decode`."
msgstr ""
"è§£å†³æ–¹æ¡ˆæ˜¯åˆ©ç”¨åº•å±‚è§£ç æ¥å£å»æ•è·ç¼–ç åºåˆ—ä¸å®Œæ•´çš„æƒ…å†µã€‚è¿™éƒ¨åˆ†ä»£ç å·²ç»æ˜¯ç°æˆçš„ï¼šå†…ç½®å‡½æ•° :func:`open` "
"å¯ä»¥è¿”å›ä¸€ä¸ªæ–‡ä»¶ç±»çš„å¯¹è±¡ï¼Œè¯¥å¯¹è±¡è®¤ä¸ºæ–‡ä»¶çš„å†…å®¹é‡‡ç”¨æŒ‡å®šçš„ç¼–ç ï¼Œ:meth:`~io.TextIOBase.read` å’Œ "
":meth:`~io.TextIOBase.write` ç­‰æ–¹æ³•æ¥å— Unicode å‚æ•°ã€‚åªè¦ç”¨ :func:`open` çš„ *encoding* "
"å’Œ *errors* å‚æ•°å³å¯ï¼Œå‚æ•°é‡Šä¹‰åŒ :meth:`str.encode` å’Œ :meth:`bytes.decode` ã€‚"

#: ../../howto/unicode.rst:574
msgid "Reading Unicode from a file is therefore simple::"
msgstr "å› æ­¤ä»æ–‡ä»¶è¯»å– Unicode å°±æ¯”è¾ƒç®€å•äº†ï¼š"

#: ../../howto/unicode.rst:576
msgid ""
"with open('unicode.txt', encoding='utf-8') as f:\n"
"    for line in f:\n"
"        print(repr(line))"
msgstr ""
"with open('unicode.txt', encoding='utf-8') as f:\n"
"    for line in f:\n"
"        print(repr(line))"

#: ../../howto/unicode.rst:580
msgid ""
"It's also possible to open files in update mode, allowing both reading and "
"writing::"
msgstr "ä¹Ÿå¯ä»¥åœ¨æ›´æ–°æ¨¡å¼ä¸‹æ‰“å¼€æ–‡ä»¶ï¼Œä»¥ä¾¿åŒæ—¶è¯»å–å’Œå†™å…¥ï¼š"

#: ../../howto/unicode.rst:583
msgid ""
"with open('test', encoding='utf-8', mode='w+') as f:\n"
"    f.write('\\u4500 blah blah blah\\n')\n"
"    f.seek(0)\n"
"    print(repr(f.readline()[:1]))"
msgstr ""
"with open('test', encoding='utf-8', mode='w+') as f:\n"
"    f.write('\\u4500 blah blah blah\\n')\n"
"    f.seek(0)\n"
"    print(repr(f.readline()[:1]))"

#: ../../howto/unicode.rst:588
msgid ""
"The Unicode character ``U+FEFF`` is used as a byte-order mark (BOM), and is "
"often written as the first character of a file in order to assist with "
"autodetection of the file's byte ordering.  Some encodings, such as UTF-16, "
"expect a BOM to be present at the start of a file; when such an encoding is "
"used, the BOM will be automatically written as the first character and will "
"be silently dropped when the file is read.  There are variants of these "
"encodings, such as 'utf-16-le' and 'utf-16-be' for little-endian and big-"
"endian encodings, that specify one particular byte ordering and don't skip "
"the BOM."
msgstr ""
"Unicode å­—ç¬¦ ``U+FEFF`` ç”¨ä½œå­—èŠ‚é¡ºåºæ ‡è®°ï¼ˆBOMï¼‰ï¼Œé€šå¸¸ä½œä¸ºæ–‡ä»¶çš„ç¬¬ä¸€ä¸ªå­—ç¬¦å†™å…¥ï¼Œä»¥å¸®åŠ©è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶çš„å­—èŠ‚é¡ºåºã€‚æŸäº›ç¼–ç ï¼ˆä¾‹å¦‚ "
"UTF-16ï¼‰æœŸæœ›åœ¨æ–‡ä»¶å¼€å¤´å‡ºç° BOMï¼›å½“é‡‡ç”¨è¿™ç§ç¼–ç æ—¶ï¼ŒBOM å°†è‡ªåŠ¨ä½œä¸ºç¬¬ä¸€ä¸ªå­—ç¬¦å†™å…¥ï¼Œå¹¶åœ¨è¯»å–æ–‡ä»¶æ—¶ä¼šé™é»˜åˆ é™¤ã€‚è¿™äº›ç¼–ç æœ‰å¤šç§å˜ä½“ï¼Œä¾‹å¦‚ç”¨äº "
"little-endian å’Œ big-endian ç¼–ç çš„ â€œutf-16-leâ€ å’Œ â€œutf-16-beâ€ï¼Œä¼šæŒ‡å®šä¸€ç§ç‰¹å®šçš„å­—èŠ‚é¡ºåºå¹¶ä¸”ä¸ä¼šå¿½ç•¥ "
"BOMã€‚"

#: ../../howto/unicode.rst:597
msgid ""
"In some areas, it is also convention to use a \"BOM\" at the start of UTF-8 "
"encoded files; the name is misleading since UTF-8 is not byte-order "
"dependent. The mark simply announces that the file is encoded in UTF-8.  For"
" reading such files, use the 'utf-8-sig' codec to automatically skip the "
"mark if present."
msgstr ""
"åœ¨æŸäº›åœ°åŒºï¼Œä¹ æƒ¯åœ¨ UTF-8 ç¼–ç æ–‡ä»¶çš„å¼€å¤´ç”¨ä¸Šâ€œBOMâ€ï¼›æ­¤åç§°å…·æœ‰è¯¯å¯¼æ€§ï¼Œå› ä¸º UTF-8 ä¸å­—èŠ‚é¡ºåºæ— å…³ã€‚æ­¤æ ‡è®°åªæ˜¯å£°æ˜è¯¥æ–‡ä»¶ä»¥ UTF-8 "
"ç¼–ç ã€‚è¦è¯»å–æ­¤ç±»æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨â€œutf-8-sigâ€ç¼–è§£ç å™¨è‡ªåŠ¨å¿½ç•¥æ­¤æ ‡è®°ã€‚"

#: ../../howto/unicode.rst:604
msgid "Unicode filenames"
msgstr "Unicode æ–‡ä»¶å"

#: ../../howto/unicode.rst:606
msgid ""
"Most of the operating systems in common use today support filenames that "
"contain arbitrary Unicode characters.  Usually this is implemented by "
"converting the Unicode string into some encoding that varies depending on "
"the system.  Today Python is converging on using UTF-8: Python on MacOS has "
"used UTF-8 for several versions, and Python 3.6 switched to using UTF-8 on "
"Windows as well.  On Unix systems, there will only be a :term:`filesystem "
"encoding <filesystem encoding and error handler>`. if you've set the "
"``LANG`` or ``LC_CTYPE`` environment variables; if you haven't, the default "
"encoding is again UTF-8."
msgstr ""
"å½“ä»Šå¤§å¤šæ•°æ“ä½œç³»ç»Ÿéƒ½æ”¯æŒåŒ…å«ä»»æ„ Unicode å­—ç¬¦çš„æ–‡ä»¶åã€‚ é€šå¸¸è¿™æ˜¯é€šè¿‡å°† Unicode å­—ç¬¦ä¸²è½¬æ¢ä¸ºæŸç§æ ¹æ®å…·ä½“ç³»ç»Ÿè€Œå®šçš„ç¼–ç æ ¼å¼æ¥å®ç°çš„ã€‚ "
"å¦‚ä»Šçš„ Python å€¾å‘äºä½¿ç”¨ UTF-8ï¼šMacOS ä¸Šçš„ Python å·²ç»åœ¨å¤šä¸ªç‰ˆæœ¬ä¸­ä½¿ç”¨äº† UTF-8ï¼Œè€Œ Python 3.6 ä¹Ÿå·²åœ¨ "
"Windows ä¸Šæ”¹ç”¨äº† UTF-8ã€‚ åœ¨ Unix ç³»ç»Ÿä¸­ï¼Œå°†åªæœ‰ä¸€ä¸ª :term:`æ–‡ä»¶ç³»ç»Ÿç¼–ç æ ¼å¼ <filesystem encoding "
"and error handler>`ã€‚ å¦‚æœä½ å·²è®¾ç½®äº† ``LANG`` æˆ– ``LC_CTYPE`` ç¯å¢ƒå˜é‡çš„è¯ï¼›å¦‚æœæœªè®¾ç½®ï¼Œåˆ™é»˜è®¤ç¼–ç æ ¼å¼è¿˜æ˜¯ "
"UTF-8ã€‚"

#: ../../howto/unicode.rst:616
msgid ""
"The :func:`sys.getfilesystemencoding` function returns the encoding to use "
"on your current system, in case you want to do the encoding manually, but "
"there's not much reason to bother.  When opening a file for reading or "
"writing, you can usually just provide the Unicode string as the filename, "
"and it will be automatically converted to the right encoding for you::"
msgstr ""
":func:`sys.getfilesystemencoding` "
"å‡½æ•°å°†è¿”å›è¦åœ¨å½“å‰ç³»ç»Ÿé‡‡ç”¨çš„ç¼–ç ï¼Œè‹¥æƒ³æ‰‹åŠ¨è¿›è¡Œç¼–ç æ—¶å³å¯ç”¨åˆ°ï¼Œä½†æ— éœ€å¤šè™‘ã€‚åœ¨æ‰“å¼€æ–‡ä»¶è¿›è¡Œè¯»å†™æ—¶ï¼Œé€šå¸¸åªéœ€æä¾› Unicode "
"å­—ç¬¦ä¸²ä½œä¸ºæ–‡ä»¶åï¼Œä¼šè‡ªåŠ¨è½¬æ¢ä¸ºåˆé€‚çš„ç¼–ç æ ¼å¼ï¼š"

#: ../../howto/unicode.rst:622
msgid ""
"filename = 'filename\\u4500abc'\n"
"with open(filename, 'w') as f:\n"
"    f.write('blah\\n')"
msgstr ""
"filename = 'filename\\u4500abc'\n"
"with open(filename, 'w') as f:\n"
"    f.write('blah\\n')"

#: ../../howto/unicode.rst:626
msgid ""
"Functions in the :mod:`os` module such as :func:`os.stat` will also accept "
"Unicode filenames."
msgstr ":mod:`os` æ¨¡å—ä¸­çš„å‡½æ•°ä¹Ÿèƒ½æ¥å— Unicode æ–‡ä»¶åï¼Œå¦‚ :func:`os.stat` ã€‚"

#: ../../howto/unicode.rst:629
msgid ""
"The :func:`os.listdir` function returns filenames, which raises an issue: "
"should it return the Unicode version of filenames, or should it return bytes"
" containing the encoded versions?  :func:`os.listdir` can do both, depending"
" on whether you provided the directory path as bytes or a Unicode string.  "
"If you pass a Unicode string as the path, filenames will be decoded using "
"the filesystem's encoding and a list of Unicode strings will be returned, "
"while passing a byte path will return the filenames as bytes.  For example, "
"assuming the default :term:`filesystem encoding <filesystem encoding and "
"error handler>` is UTF-8, running the following program::"
msgstr ""
":func:`os.listdir` å‡½æ•°è¿”å›æ–‡ä»¶åï¼Œè¿™å¼•å‘äº†ä¸€ä¸ªé—®é¢˜ï¼šå®ƒåº”è¯¥è¿”å›æ–‡ä»¶åçš„ Unicode ç‰ˆæœ¬ï¼Œè¿˜æ˜¯åº”è¯¥è¿”å›åŒ…å«å·²ç¼–ç ç‰ˆæœ¬çš„å­—èŠ‚ä¸²ï¼Ÿ "
"è¿™ä¸¤è€… :func:`os.listdir` éƒ½èƒ½åšåˆ°ï¼Œå…·ä½“å–å†³äºä½ ç»™å‡ºçš„ç›®å½•è·¯å¾„æ˜¯å­—èŠ‚ä¸²è¿˜æ˜¯ Unicode å­—ç¬¦ä¸²å½¢å¼çš„ã€‚ å¦‚æœä½ ä¼ å…¥ä¸€ä¸ª "
"Unicode å­—ç¬¦ä¸²ä½œä¸ºè·¯å¾„ï¼Œæ–‡ä»¶åå°†ä½¿ç”¨æ–‡ä»¶ç³»ç»Ÿçš„ç¼–ç æ ¼å¼è¿›è¡Œè§£ç å¹¶è¿”å›ä¸€ä¸ª Unicode "
"å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œè€Œä¼ å…¥ä¸€ä¸ªå­—èŠ‚ä¸²å½¢å¼çš„è·¯å¾„åˆ™å°†è¿”å›å­—èŠ‚ä¸²å½¢å¼çš„æ–‡ä»¶åã€‚ ä¾‹å¦‚ï¼Œå‡å®šé»˜è®¤ :term:`æ–‡ä»¶ç³»ç»Ÿç¼–ç  <filesystem encoding"
" and error handler>` ä¸º UTF-8ï¼Œè¿è¡Œä»¥ä¸‹ç¨‹åº::"

#: ../../howto/unicode.rst:639
msgid ""
"fn = 'filename\\u4500abc'\n"
"f = open(fn, 'w')\n"
"f.close()\n"
"\n"
"import os\n"
"print(os.listdir(b'.'))\n"
"print(os.listdir('.'))"
msgstr ""
"fn = 'filename\\u4500abc'\n"
"f = open(fn, 'w')\n"
"f.close()\n"
"\n"
"import os\n"
"print(os.listdir(b'.'))\n"
"print(os.listdir('.'))"

#: ../../howto/unicode.rst:647
msgid "will produce the following output:"
msgstr "å°†äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š"

#: ../../howto/unicode.rst:649
msgid ""
"$ python listdir-test.py\n"
"[b'filename\\xe4\\x94\\x80abc', ...]\n"
"['filename\\u4500abc', ...]"
msgstr ""
"$ python listdir-test.py\n"
"[b'filename\\xe4\\x94\\x80abc', ...]\n"
"['filename\\u4500abc', ...]"

#: ../../howto/unicode.rst:655
msgid ""
"The first list contains UTF-8-encoded filenames, and the second list "
"contains the Unicode versions."
msgstr "ç¬¬ä¸€ä¸ªåˆ—è¡¨åŒ…å« UTF-8 ç¼–ç çš„æ–‡ä»¶åï¼Œç¬¬äºŒä¸ªåˆ—è¡¨åˆ™åŒ…å« Unicode ç‰ˆæœ¬çš„ã€‚"

#: ../../howto/unicode.rst:658
msgid ""
"Note that on most occasions, you should can just stick with using Unicode "
"with these APIs.  The bytes APIs should only be used on systems where "
"undecodable file names can be present; that's pretty much only Unix systems "
"now."
msgstr ""
"è¯·æ³¨æ„ï¼Œå¤§å¤šæ—¶å€™åº”è¯¥åšæŒç”¨è¿™äº› API å¤„ç† Unicodeã€‚å­—èŠ‚ä¸² API åº”è¯¥ä»…ç”¨äºå¯èƒ½å­˜åœ¨ä¸å¯è§£ç æ–‡ä»¶åçš„ç³»ç»Ÿï¼›ç°åœ¨å‡ ä¹ä»…å‰© Unix ç³»ç»Ÿäº†ã€‚"

#: ../../howto/unicode.rst:665
msgid "Tips for Writing Unicode-aware Programs"
msgstr "è¯†åˆ« Unicode çš„ç¼–ç¨‹æŠ€å·§"

#: ../../howto/unicode.rst:667
msgid ""
"This section provides some suggestions on writing software that deals with "
"Unicode."
msgstr "æœ¬èŠ‚æä¾›äº†ä¸€äº›å…³äºç¼–å†™ Unicode å¤„ç†è½¯ä»¶çš„å»ºè®®ã€‚"

#: ../../howto/unicode.rst:670
msgid "The most important tip is:"
msgstr "æœ€é‡è¦çš„æŠ€å·§å¦‚ä¸‹ï¼š"

#: ../../howto/unicode.rst:672
msgid ""
"Software should only work with Unicode strings internally, decoding the "
"input data as soon as possible and encoding the output only at the end."
msgstr "ç¨‹åºåº”åªåœ¨å†…éƒ¨å¤„ç† Unicode å­—ç¬¦ä¸²ï¼Œå°½å¿«å¯¹è¾“å…¥æ•°æ®è¿›è¡Œè§£ç ï¼Œå¹¶åªåœ¨æœ€åå¯¹è¾“å‡ºè¿›è¡Œç¼–ç ã€‚"

#: ../../howto/unicode.rst:675
msgid ""
"If you attempt to write processing functions that accept both Unicode and "
"byte strings, you will find your program vulnerable to bugs wherever you "
"combine the two different kinds of strings.  There is no automatic encoding "
"or decoding: if you do e.g. ``str + bytes``, a :exc:`TypeError` will be "
"raised."
msgstr ""
"å¦‚æœå°è¯•ç¼–å†™çš„å¤„ç†å‡½æ•°å¯¹ Unicode "
"å’Œå­—èŠ‚ä¸²å½¢å¼çš„å­—ç¬¦ä¸²éƒ½èƒ½æ¥å—ï¼Œå°±ä¼šå‘ç°ç»„åˆä½¿ç”¨ä¸¤ç§ä¸åŒç±»å‹çš„å­—ç¬¦ä¸²æ—¶ï¼Œå®¹æ˜“äº§ç”Ÿå·®é”™ã€‚æ²¡åŠæ³•åšåˆ°è‡ªåŠ¨ç¼–ç æˆ–è§£ç ï¼šå¦‚æœæ‰§è¡Œ ``str + "
"bytes``ï¼Œåˆ™ä¼šè§¦å‘ :exc:`TypeError`ã€‚"

#: ../../howto/unicode.rst:680
msgid ""
"When using data coming from a web browser or some other untrusted source, a "
"common technique is to check for illegal characters in a string before using"
" the string in a generated command line or storing it in a database.  If "
"you're doing this, be careful to check the decoded string, not the encoded "
"bytes data; some encodings may have interesting properties, such as not "
"being bijective or not being fully ASCII-compatible.  This is especially "
"true if the input data also specifies the encoding, since the attacker can "
"then choose a clever way to hide malicious text in the encoded bytestream."
msgstr ""
"å½“è¦ä½¿ç”¨çš„æ•°æ®æ¥è‡ª Web "
"æµè§ˆå™¨æˆ–å…¶ä»–ä¸å—ä¿¡æ¥æºæ—¶ï¼Œå¸¸ç”¨æŠ€æœ¯æ˜¯åœ¨ç”¨è¯¥å­—ç¬¦ä¸²ç”Ÿæˆå‘½ä»¤è¡Œä¹‹å‰ï¼Œæˆ–è¦å­˜å…¥æ•°æ®åº“ä¹‹å‰ï¼Œå…ˆæ£€æŸ¥å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«éæ³•å­—ç¬¦ã€‚è¯·ä»”ç»†æ£€æŸ¥è§£ç åçš„å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯ç¼–ç æ ¼å¼çš„å­—èŠ‚ä¸²æ•°æ®ï¼›æœ‰äº›ç¼–ç å¯èƒ½å…·å¤‡ä¸€äº›æœ‰è¶£çš„ç‰¹æ€§ï¼Œä¾‹å¦‚ä¸"
" ASCII ä¸æ˜¯ä¸€ä¸€å¯¹åº”æˆ–ä¸å®Œå…¨å…¼å®¹ã€‚å¦‚æœè¾“å…¥æ•°æ®è¿˜æŒ‡å®šäº†ç¼–ç æ ¼å¼ï¼Œåˆ™å°¤å…¶å¦‚æ­¤ï¼Œå› ä¸ºæ”»å‡»è€…å¯ä»¥é€‰æ‹©ä¸€ç§å·§å¦™çš„æ–¹å¼å°†æ¶æ„æ–‡æœ¬éšè—åœ¨ç»è¿‡ç¼–ç çš„å­—èŠ‚æµä¸­ã€‚"

#: ../../howto/unicode.rst:691
msgid "Converting Between File Encodings"
msgstr "åœ¨æ–‡ä»¶ç¼–ç æ ¼å¼ä¹‹é—´è¿›è¡Œè½¬æ¢"

#: ../../howto/unicode.rst:693
msgid ""
"The :class:`~codecs.StreamRecoder` class can transparently convert between "
"encodings, taking a stream that returns data in encoding #1 and behaving "
"like a stream returning data in encoding #2."
msgstr ""
":class:`~codecs.StreamRecoder` ç±»å¯ä»¥åœ¨ä¸¤ç§ç¼–ç ä¹‹é—´é€æ˜åœ°è¿›è¡Œè½¬æ¢ï¼Œå‚æ•°ä¸ºç¼–ç æ ¼å¼ä¸º #1 "
"çš„æ•°æ®æµï¼Œè¡¨ç°è¡Œä¸ºåˆ™æ˜¯ç¼–ç æ ¼å¼ä¸º #2 çš„æ•°æ®æµã€‚"

#: ../../howto/unicode.rst:697
msgid ""
"For example, if you have an input file *f* that's in Latin-1, you can wrap "
"it with a :class:`~codecs.StreamRecoder` to return bytes encoded in UTF-8::"
msgstr ""
"å‡è®¾è¾“å…¥æ–‡ä»¶ *f* é‡‡ç”¨ Latin-1 ç¼–ç æ ¼å¼ï¼Œå³å¯ç”¨ :class:`~codecs.StreamRecoder` åŒ…è£…åè¿”å› UTF-8 "
"ç¼–ç çš„å­—èŠ‚ä¸²ï¼š"

#: ../../howto/unicode.rst:701
msgid ""
"new_f = codecs.StreamRecoder(f,\n"
"    # en/decoder: used by read() to encode its results and\n"
"    # by write() to decode its input.\n"
"    codecs.getencoder('utf-8'), codecs.getdecoder('utf-8'),\n"
"\n"
"    # reader/writer: used to read and write to the stream.\n"
"    codecs.getreader('latin-1'), codecs.getwriter('latin-1') )"
msgstr ""
"new_f = codecs.StreamRecoder(f,\n"
"    # en/decoder: è¢« read() ç”¨æ¥ç¼–ç å…¶ç»“æœ\n"
"    # å¹¶è¢« write() ç”¨æ¥è§£ç å…¶è¾“å…¥ã€‚\n"
"    codecs.getencoder('utf-8'), codecs.getdecoder('utf-8'),\n"
"\n"
"    # reader/writer: ç”¨äºè¯»å–å’Œå†™å…¥æµã€‚\n"
"    codecs.getreader('latin-1'), codecs.getwriter('latin-1') )"

#: ../../howto/unicode.rst:711
msgid "Files in an Unknown Encoding"
msgstr "ç¼–ç æ ¼å¼æœªçŸ¥çš„æ–‡ä»¶"

#: ../../howto/unicode.rst:713
msgid ""
"What can you do if you need to make a change to a file, but don't know the "
"file's encoding?  If you know the encoding is ASCII-compatible and only want"
" to examine or modify the ASCII parts, you can open the file with the "
"``surrogateescape`` error handler::"
msgstr ""
"è‹¥éœ€å¯¹æ–‡ä»¶è¿›è¡Œä¿®æ”¹ï¼Œä½†ä¸çŸ¥é“æ–‡ä»¶çš„ç¼–ç ï¼Œé‚£è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿå¦‚æœå·²çŸ¥ç¼–ç æ ¼å¼ä¸ ASCII å…¼å®¹ï¼Œå¹¶ä¸”åªæƒ³æŸ¥çœ‹æˆ–ä¿®æ”¹ ASCII éƒ¨åˆ†ï¼Œåˆ™å¯åˆ©ç”¨ "
"``surrogateescape`` é”™è¯¯å¤„ç† handler æ‰“å¼€æ–‡ä»¶ï¼š"

#: ../../howto/unicode.rst:718
msgid ""
"with open(fname, 'r', encoding=\"ascii\", errors=\"surrogateescape\") as f:\n"
"    data = f.read()\n"
"\n"
"# make changes to the string 'data'\n"
"\n"
"with open(fname + '.new', 'w',\n"
"          encoding=\"ascii\", errors=\"surrogateescape\") as f:\n"
"    f.write(data)"
msgstr ""
"with open(fname, 'r', encoding=\"ascii\", errors=\"surrogateescape\") as f:\n"
"    data = f.read()\n"
"\n"
"# å¯¹å­—ç¬¦ä¸²â€œdataâ€è¿›è¡Œæ›´æ”¹\n"
"\n"
"with open(fname + '.new', 'w',\n"
"          encoding=\"ascii\", errors=\"surrogateescape\") as f:\n"
"    f.write(data)"

#: ../../howto/unicode.rst:727
msgid ""
"The ``surrogateescape`` error handler will decode any non-ASCII bytes as "
"code points in a special range running from U+DC80 to U+DCFF.  These code "
"points will then turn back into the same bytes when the ``surrogateescape`` "
"error handler is used to encode the data and write it back out."
msgstr ""
"``surrogateescape`` é”™è¯¯å¤„ç† handler ä¼šæŠŠæ‰€æœ‰é ASCII å­—èŠ‚è§£ç ä¸º U+DC80 è‡³ U+DCFF "
"è¿™ä¸€ç‰¹æ®ŠèŒƒå›´çš„ç ä½ã€‚å½“ ``surrogateescape`` é”™è¯¯å¤„ç† handlerç”¨äºæ•°æ®ç¼–ç å¹¶å›å†™æ—¶ï¼Œè¿™äº›ç ä½å°†è½¬æ¢å›åŸæ ·ã€‚"

#: ../../howto/unicode.rst:737
msgid ""
"One section of `Mastering Python 3 Input/Output "
"<https://pyvideo.org/video/289/pycon-2010--mastering-python-3-i-o>`_, a "
"PyCon 2010 talk by David Beazley, discusses text processing and binary data "
"handling."
msgstr ""
"David Beazley åœ¨ PyCon 2010 ä¸Šçš„æ¼”è®² `æŒæ¡ Python 3 è¾“å…¥/è¾“å‡º "
"<https://pyvideo.org/video/289/pycon-2010--mastering-python-3-io>`_ "
"ä¸­ï¼Œæœ‰ä¸€èŠ‚è®¨è®ºäº†æ–‡æœ¬å’ŒäºŒè¿›åˆ¶æ•°æ®çš„å¤„ç†ã€‚"

#: ../../howto/unicode.rst:741
msgid ""
"The `PDF slides for Marc-AndrÃ© Lemburg's presentation \"Writing Unicode-"
"aware Applications in Python\" "
"<https://downloads.egenix.com/python/LSM2005-Developing-Unicode-aware-"
"applications-in-Python.pdf>`_ discuss questions of character encodings as "
"well as how to internationalize and localize an application.  These slides "
"cover Python 2.x only."
msgstr ""
"`Marc-AndrÃ© Lemburg æ¼”ç¤ºçš„PDF å¹»ç¯ç‰‡â€œåœ¨ Python ä¸­ç¼–å†™æ”¯æŒ Unicode çš„åº”ç”¨ç¨‹åºâ€  "
"<https://downloads.egenix.com/python/LSM2005-Developing-Unicode-aware-"
"applications-in-Python.pdf>`_ ï¼Œè®¨è®ºäº†å­—ç¬¦ç¼–ç é—®é¢˜ä»¥åŠå¦‚ä½•å›½é™…åŒ–å’Œæœ¬åœ°åŒ–åº”ç”¨ç¨‹åºã€‚è¿™äº›å¹»ç¯ç‰‡ä»…æ¶µç›– Python 2.xã€‚"

#: ../../howto/unicode.rst:747
msgid ""
"`The Guts of Unicode in Python <https://pyvideo.org/video/1768/the-guts-of-"
"unicode-in-python>`_ is a PyCon 2013 talk by Benjamin Peterson that "
"discusses the internal Unicode representation in Python 3.3."
msgstr ""
"`Python Unicode å®è´¨ <https://pyvideo.org/video/1768/the-guts-of-unicode-in-"
"python>`_ æ˜¯ Benjamin Peterson åœ¨ PyCon 2013 ä¸Šçš„æ¼”è®²ï¼Œè®¨è®ºäº† Unicode  åœ¨ Python 3.3 "
"ä¸­çš„å†…éƒ¨è¡¨ç¤ºã€‚"

#: ../../howto/unicode.rst:754
msgid "Acknowledgements"
msgstr "è‡´è°¢"

#: ../../howto/unicode.rst:756
msgid ""
"The initial draft of this document was written by Andrew Kuchling. It has "
"since been revised further by Alexander Belopolsky, Georg Brandl, Andrew "
"Kuchling, and Ezio Melotti."
msgstr ""
"æœ¬æ–‡åˆç¨¿ç”± Andrew Kuchling æ’°å†™ã€‚æ­¤åï¼ŒAlexander Belopolskyã€Georg Brandlã€Andrew "
"Kuchling å’Œ Ezio Melotti ä½œäº†è¿›ä¸€æ­¥ä¿®è®¢ã€‚"

#: ../../howto/unicode.rst:760
msgid ""
"Thanks to the following people who have noted errors or offered suggestions "
"on this article: Ã‰ric Araujo, Nicholas Bastin, Nick Coghlan, Marius "
"Gedminas, Kent Johnson, Ken Krugler, Marc-AndrÃ© Lemburg, Martin von LÃ¶wis, "
"Terry J. Reedy, Serhiy Storchaka, Eryk Sun, Chad Whitacre, Graham Wideman."
msgstr ""
"æ„Ÿè°¢ä»¥ä¸‹å„ä½æŒ‡å‡ºæœ¬æ–‡é”™è¯¯æˆ–æå‡ºå»ºè®®ï¼šÃ‰ric Araujoã€Nicholas Bastinã€Nick Coghlanã€Marius "
"Gedminasã€Kent Johnsonã€Ken Kruglerã€Marc-AndrÃ© Lemburgã€Martin von LÃ¶wisã€Terry "
"J. Reedyã€Serhiy Storchaka , Eryk Sun, Chad Whitacre, Graham Widemanã€‚"
