# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2001-2021, Python Software Foundation
# This file is distributed under the same license as the Python package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# 汪心禾 <wangxinhe06@gmail.com>, 2020
# Freesand Leo <yuqinju@163.com>, 2020
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python 3.8\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-01-01 16:06+0000\n"
"PO-Revision-Date: 2020-05-30 12:13+0000\n"
"Last-Translator: Freesand Leo <yuqinju@163.com>, 2020\n"
"Language-Team: Chinese (China) (https://www.transifex.com/python-doc/teams/5390/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../library/urllib.robotparser.rst:2
msgid ":mod:`urllib.robotparser` ---  Parser for robots.txt"
msgstr ":mod:`urllib.robotparser` --- robots.txt 语法分析程序"

#: ../../library/urllib.robotparser.rst:10
msgid "**Source code:** :source:`Lib/urllib/robotparser.py`"
msgstr "**源代码：** :source:`Lib/urllib/robotparser.py`"

#: ../../library/urllib.robotparser.rst:20
msgid ""
"This module provides a single class, :class:`RobotFileParser`, which answers"
" questions about whether or not a particular user agent can fetch a URL on "
"the Web site that published the :file:`robots.txt` file.  For more details "
"on the structure of :file:`robots.txt` files, see "
"http://www.robotstxt.org/orig.html."
msgstr ""
"此模块提供了一个单独的类 :class:`RobotFileParser`，它可以回答关于某个特定用户代理是否能在 Web 站点获取发布 "
":file:`robots.txt` 文件的 URL 的问题。 有关 :file:`robots.txt` 文件结构的更多细节请参阅 "
"http://www.robotstxt.org/orig.html。"

#: ../../library/urllib.robotparser.rst:28
msgid ""
"This class provides methods to read, parse and answer questions about the "
":file:`robots.txt` file at *url*."
msgstr "这个类提供了一些可以读取、解析和回答关于 *url* 上的 :file:`robots.txt` 文件的问题的方法。"

#: ../../library/urllib.robotparser.rst:33
msgid "Sets the URL referring to a :file:`robots.txt` file."
msgstr "设置指向 :file:`robots.txt` 文件的 URL。"

#: ../../library/urllib.robotparser.rst:37
msgid "Reads the :file:`robots.txt` URL and feeds it to the parser."
msgstr "读取 :file:`robots.txt` URL 并将其输入解析器。"

#: ../../library/urllib.robotparser.rst:41
msgid "Parses the lines argument."
msgstr "解析行参数。"

#: ../../library/urllib.robotparser.rst:45
msgid ""
"Returns ``True`` if the *useragent* is allowed to fetch the *url* according "
"to the rules contained in the parsed :file:`robots.txt` file."
msgstr ""
"如果允许 *useragent* 按照被解析 :file:`robots.txt` 文件中的规则来获取 *url* 则返回 ``True``。"

#: ../../library/urllib.robotparser.rst:51
msgid ""
"Returns the time the ``robots.txt`` file was last fetched.  This is useful "
"for long-running web spiders that need to check for new ``robots.txt`` files"
" periodically."
msgstr ""
"返回最近一次获取 ``robots.txt`` 文件的时间。 这适用于需要定期检查 ``robots.txt`` 文件更新情况的长时间运行的网页爬虫。"

#: ../../library/urllib.robotparser.rst:57
msgid ""
"Sets the time the ``robots.txt`` file was last fetched to the current time."
msgstr "将最近一次获取 ``robots.txt`` 文件的时间设置为当前时间。"

#: ../../library/urllib.robotparser.rst:62
msgid ""
"Returns the value of the ``Crawl-delay`` parameter from ``robots.txt`` for "
"the *useragent* in question.  If there is no such parameter or it doesn't "
"apply to the *useragent* specified or the ``robots.txt`` entry for this "
"parameter has invalid syntax, return ``None``."
msgstr ""
"为指定的 *useragent* 从 ``robots.txt`` 返回 ``Crawl-delay`` 形参。 如果此形参不存在或不适用于指定的 "
"*useragent* 或者此形参的 ``robots.txt`` 条目存在语法错误，则返回 ``None``。"

#: ../../library/urllib.robotparser.rst:71
msgid ""
"Returns the contents of the ``Request-rate`` parameter from ``robots.txt`` "
"as a :term:`named tuple` ``RequestRate(requests, seconds)``. If there is no "
"such parameter or it doesn't apply to the *useragent* specified or the "
"``robots.txt`` entry for this parameter has invalid syntax, return ``None``."
msgstr ""
"以 :term:`named tuple` ``RequestRate(requests, seconds)`` 的形式从 ``robots.txt``"
" 返回 ``Request-rate`` 形参的内容。 如果此形参不存在或不适用于指定的 *useragent* 或者此形参的 "
"``robots.txt`` 条目存在语法错误，则返回 ``None``。"

#: ../../library/urllib.robotparser.rst:81
msgid ""
"Returns the contents of the ``Sitemap`` parameter from ``robots.txt`` in the"
" form of a :func:`list`. If there is no such parameter or the ``robots.txt``"
" entry for this parameter has invalid syntax, return ``None``."
msgstr ""
"以 :func:`list` 的形式从 ``robots.txt`` 返回 ``Sitemap`` 形参的内容。 如果此形参不存在或者此形参的 "
"``robots.txt`` 条目存在语法错误，则返回 ``None``。"

#: ../../library/urllib.robotparser.rst:89
msgid ""
"The following example demonstrates basic use of the :class:`RobotFileParser`"
" class::"
msgstr "下面的例子演示了 :class:`RobotFileParser` 类的基本用法::"
